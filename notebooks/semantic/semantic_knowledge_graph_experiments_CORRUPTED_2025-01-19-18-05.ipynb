{
 "cells": [
  {
   "cell_type": "code",
   "source": "# üé® Create Comprehensive Linked Data Visualization\nyfiles_comprehensive = comprehensive_viz.create_yfiles_comprehensive_visualization()\n\nif yfiles_comprehensive:\n    print(\"\\nüåü **LINKED DATA REUSABILITY DEMONSTRATION**\")\n    print(\"=\" * 60)\n    print(\"üî¥ Red nodes: Gist Foundation Ontology (Level 1)\")\n    print(\"üîµ Blue nodes: Data Business Canvas Bridge (Level 2)\")  \n    print(\"üü¢ Green nodes: SOW Contract Ontology (Level 3)\")\n    print(\"üü† Orange nodes: Complete SOW Implementation (Level 3+)\")\n    print(\"üü£ Purple nodes: Test Data Instances (Level 4)\")\n    print(\"üî∑ Teal nodes: Inference Rules\")\n    print()\n    print(\"üí° **What This Shows:**\")\n    print(\"  ‚Ä¢ How ontologies build upon each other\")\n    print(\"  ‚Ä¢ Semantic inheritance and extension patterns\")\n    print(\"  ‚Ä¢ Real linked data in action\")\n    print(\"  ‚Ä¢ Cross-ontology connectivity\")\n    print(\"  ‚Ä¢ Professional semantic architecture\")\n    print()\n    \n    display(yfiles_comprehensive)\nelse:\n    print(\"‚ö†Ô∏è Comprehensive visualization not available\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# üîß Comprehensive Linked Data Visualizer\nclass ComprehensiveLinkedDataVisualizer:\n    \"\"\"Comprehensive visualizer for demonstrating linked data and ontology reusability\"\"\"\n    \n    def __init__(self, kg_instance):\n        self.kg = kg_instance\n        \n        # Define ontology color scheme for linked data demonstration\n        self.ontology_colors = {\n            'gist': '#E74C3C',        # Red - Foundation ontology\n            'bridge': '#3498DB',      # Blue - Bridge ontology  \n            'sow': '#2ECC71',         # Green - SOW ontology\n            'complete-sow': '#F39C12', # Orange - Complete SOW\n            'test-data': '#9B59B6',   # Purple - Test instances\n            'inference': '#1ABC9C'     # Teal - Inference rules\n        }\n        \n        self.level_hierarchy = {\n            1: 'Foundation (Gist)',\n            2: 'Business Layer (DBC)',\n            3: 'Contract Layer (SOW)', \n            4: 'Execution Layer (Data Contract)'\n        }\n    \n    def determine_ontology_source(self, uri):\n        \"\"\"Determine which ontology a URI belongs to\"\"\"\n        uri_str = str(uri)\n        \n        if 'gistCore' in uri_str:\n            return 'gist'\n        elif 'gist-dbc-bridge' in uri_str:\n            return 'bridge'\n        elif 'complete-sow' in uri_str:\n            return 'complete-sow'\n        elif 'sow' in uri_str:\n            return 'sow'\n        elif 'test-data' in uri_str or 'TestOrg' in uri_str or 'TestCanvas' in uri_str:\n            return 'test-data'\n        elif 'inference' in uri_str:\n            return 'inference'\n        else:\n            return 'bridge'  # Default for custom ontology elements\n    \n    def get_comprehensive_graph_data(self):\n        \"\"\"Get all graph data across ontologies to show complete linked data picture\"\"\"\n        print(\"üîç Querying comprehensive linked data across all ontologies...\")\n        \n        # Query 1: All classes and their hierarchies\n        classes_query = \"\"\"\n        SELECT ?class ?superclass ?classLabel WHERE {\n            ?class a owl:Class .\n            OPTIONAL { \n                ?class rdfs:subClassOf ?superclass .\n                FILTER(isURI(?superclass))\n            }\n            OPTIONAL { ?class rdfs:label ?classLabel }\n        }\n        \"\"\"\n        \n        # Query 2: All instances and their types\n        instances_query = \"\"\"\n        SELECT ?instance ?type ?instanceLabel WHERE {\n            ?instance a ?type .\n            FILTER(\n                STRSTARTS(STR(?type), \"https://w3id.org/semanticarts/ontology/gistCore#\") ||\n                STRSTARTS(STR(?type), \"https://agentic-data-scraper.com/ontology/\")\n            )\n            OPTIONAL { ?instance rdfs:label ?instanceLabel }\n        }\n        \"\"\"\n        \n        # Query 3: All property assertions (relationships)\n        relationships_query = \"\"\"\n        SELECT ?subject ?predicate ?object WHERE {\n            ?subject ?predicate ?object .\n            FILTER(\n                STRSTARTS(STR(?predicate), \"https://w3id.org/semanticarts/ontology/gistCore#\") ||\n                STRSTARTS(STR(?predicate), \"https://agentic-data-scraper.com/ontology/\") ||\n                STR(?predicate) = \"http://www.w3.org/2000/01/rdf-schema#subClassOf\"\n            )\n            FILTER(isURI(?object))\n        }\n        \"\"\"\n        \n        # Execute all queries\n        classes_df = self.kg.query(classes_query)\n        instances_df = self.kg.query(instances_query)\n        relationships_df = self.kg.query(relationships_query)\n        \n        print(f\"‚úÖ Retrieved comprehensive data:\")\n        print(f\"  Classes: {len(classes_df)}\")\n        print(f\"  Instances: {len(instances_df)}\")\n        print(f\"  Relationships: {len(relationships_df)}\")\n        \n        return {\n            'classes': classes_df,\n            'instances': instances_df,\n            'relationships': relationships_df\n        }\n    \n    def create_comprehensive_networkx_graph(self):\n        \"\"\"Create comprehensive NetworkX graph showing all ontology connections\"\"\"\n        print(\"üåê Building comprehensive linked data graph...\")\n        \n        data = self.get_comprehensive_graph_data()\n        G = nx.DiGraph()\n        \n        # Add all classes as nodes\n        for _, row in data['classes'].iterrows():\n            class_uri = row['class']\n            source_ontology = self.determine_ontology_source(class_uri)\n            \n            G.add_node(class_uri,\n                      node_type='class',\n                      ontology=source_ontology,\n                      color=self.ontology_colors[source_ontology],\n                      label=class_uri.split('#')[-1].split('/')[-1],\n                      size=20)\n        \n        # Add instances as nodes\n        for _, row in data['instances'].iterrows():\n            instance_uri = row['instance']\n            type_uri = row['type']\n            source_ontology = self.determine_ontology_source(instance_uri)\n            \n            G.add_node(instance_uri,\n                      node_type='instance',\n                      ontology=source_ontology,\n                      color=self.ontology_colors[source_ontology],\n                      label=instance_uri.split('#')[-1].split('/')[-1],\n                      size=15)\n            \n            # Add type relationship\n            if type_uri in G.nodes():\n                G.add_edge(instance_uri, type_uri, \n                          relationship='rdf:type',\n                          edge_type='typing',\n                          color='#34495E')\n        \n        # Add property relationships\n        for _, row in data['relationships'].iterrows():\n            subject = row['subject']\n            predicate = row['predicate']\n            obj = row['object']\n            \n            if subject in G.nodes() and obj in G.nodes():\n                edge_type = 'property'\n                edge_color = '#16A085'\n                \n                if 'subClassOf' in predicate:\n                    edge_type = 'hierarchy'\n                    edge_color = '#E67E22'\n                \n                G.add_edge(subject, obj,\n                          relationship=predicate.split('#')[-1],\n                          edge_type=edge_type,\n                          color=edge_color)\n        \n        print(f\"‚úÖ Comprehensive graph built:\")\n        print(f\"  Total nodes: {len(G.nodes())}\")\n        print(f\"  Total edges: {len(G.edges())}\")\n        \n        # Print ontology distribution\n        ontology_counts = {}\n        for node, data in G.nodes(data=True):\n            ontology = data.get('ontology', 'unknown')\n            ontology_counts[ontology] = ontology_counts.get(ontology, 0) + 1\n        \n        print(f\"  Ontology distribution:\")\n        for ontology, count in ontology_counts.items():\n            print(f\"    {ontology}: {count} nodes\")\n        \n        return G\n    \n    def create_yfiles_comprehensive_visualization(self):\n        \"\"\"Create professional yFiles visualization of complete linked data graph\"\"\"\n        print(\"üé® Creating comprehensive yFiles visualization...\")\n        \n        G = self.create_comprehensive_networkx_graph()\n        \n        try:\n            from yfiles_jupyter_graphs import GraphWidget\n            \n            # Create yFiles widget with comprehensive graph\n            widget = GraphWidget(graph=G)\n            \n            # Configure advanced layout for linked data\n            widget.set_layout_algorithm('hierarchic')\n            \n            # Configure node appearance by ontology\n            widget.node_color_mapping = 'color'\n            widget.node_size_mapping = 'size'\n            widget.node_label_mapping = 'label'\n            \n            # Configure edge appearance\n            widget.edge_color_mapping = 'color'\n            widget.edge_label_mapping = 'relationship'\n            \n            print(\"‚úÖ yFiles comprehensive visualization created\")\n            print(\"üéØ Features:\")\n            print(\"  ‚Ä¢ Color-coded by source ontology\")\n            print(\"  ‚Ä¢ Hierarchical layout showing semantic levels\")\n            print(\"  ‚Ä¢ Interactive exploration of linked data\")\n            print(\"  ‚Ä¢ Full ontology reusability demonstration\")\n            \n            return widget\n            \n        except Exception as e:\n            print(f\"‚ÑπÔ∏è yFiles not available: {e}\")\n            print(\"üí° Creating Plotly fallback...\")\n            return self._create_plotly_comprehensive_fallback(G)\n    \n    def _create_plotly_comprehensive_fallback(self, G):\n        \"\"\"Create comprehensive Plotly visualization as fallback\"\"\"\n        import plotly.graph_objects as go\n        \n        # Create hierarchical layout\n        pos = nx.spring_layout(G, k=3, iterations=100)\n        \n        # Prepare traces by ontology for legend\n        ontology_traces = {}\n        \n        for ontology, color in self.ontology_colors.items():\n            ontology_traces[ontology] = {\n                'x': [], 'y': [], 'text': [],\n                'color': color, 'nodes': []\n            }\n        \n        # Organize nodes by ontology\n        for node, data in G.nodes(data=True):\n            if node in pos:\n                x, y = pos[node]\n                ontology = data.get('ontology', 'bridge')\n                \n                ontology_traces[ontology]['x'].append(x)\n                ontology_traces[ontology]['y'].append(y) \n                ontology_traces[ontology]['text'].append(data.get('label', node))\n                ontology_traces[ontology]['nodes'].append(node)\n        \n        # Create edge traces\n        edge_x, edge_y = [], []\n        for edge in G.edges():\n            if edge[0] in pos and edge[1] in pos:\n                x0, y0 = pos[edge[0]]\n                x1, y1 = pos[edge[1]]\n                edge_x.extend([x0, x1, None])\n                edge_y.extend([y0, y1, None])\n        \n        # Create figure\n        fig = go.Figure()\n        \n        # Add edges\n        fig.add_trace(go.Scatter(\n            x=edge_x, y=edge_y,\n            mode='lines',\n            line=dict(width=1, color='rgba(125,125,125,0.3)'),\n            hoverinfo='none',\n            showlegend=False\n        ))\n        \n        # Add node traces for each ontology\n        for ontology, trace_data in ontology_traces.items():\n            if trace_data['x']:  # Only add if there are nodes\n                fig.add_trace(go.Scatter(\n                    x=trace_data['x'],\n                    y=trace_data['y'],\n                    mode='markers+text',\n                    marker=dict(\n                        size=12,\n                        color=trace_data['color'],\n                        line=dict(width=2, color='white')\n                    ),\n                    text=trace_data['text'],\n                    textposition='middle center',\n                    textfont=dict(size=8),\n                    name=f\"{ontology.title()} Ontology\",\n                    hovertemplate=f\"<b>{ontology.title()}</b><br>%{{text}}<extra></extra>\"\n                ))\n        \n        # Update layout\n        fig.update_layout(\n            title=dict(\n                text='üåê Complete Linked Data Graph - Ontology Reusability',\n                font=dict(size=18),\n                x=0.5\n            ),\n            showlegend=True,\n            legend=dict(\n                orientation=\"v\",\n                yanchor=\"top\",\n                y=1,\n                xanchor=\"left\", \n                x=1.02\n            ),\n            hovermode='closest',\n            margin=dict(b=20, l=5, r=150, t=60),\n            xaxis=dict(showgrid=False, zeroline=False, showticklabels=False),\n            yaxis=dict(showgrid=False, zeroline=False, showticklabels=False),\n            plot_bgcolor='white'\n        )\n        \n        return fig\n\n# Initialize the comprehensive visualizer\ncomprehensive_viz = ComprehensiveLinkedDataVisualizer(kg)\nprint(\"üöÄ Comprehensive Linked Data Visualizer ready!\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "## üé® Advanced Semantic Visualizations\n\n**Comprehensive linked data visualization system demonstrating ontology reusability**",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Semantic Knowledge Graph Experiments\n",
    "\n",
    "**Interactive exploration of the 4-level connected ontology:**\n",
    "- **Level 1**: Gist Upper Ontology (Enterprise Foundation)\n",
    "- **Level 2**: Data Business Canvas (Business Strategy) \n",
    "- **Level 3**: SOW Contracts (Implementation Planning)\n",
    "- **Level 4**: Data Contracts (Operational Execution)\n",
    "\n",
    "**Endpoints:**\n",
    "- Fuseki Web UI: http://localhost:3030\n",
    "- SPARQL Endpoint: http://localhost:3030/ds/sparql\n",
    "- Dataset: `ds` with 3,208 triples\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup and Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages if not already installed\n",
    "import subprocess\n",
    "import sys\n",
    "\n",
    "def install_if_missing(package):\n",
    "    try:\n",
    "        __import__(package.split('[')[0])\n",
    "    except ImportError:\n",
    "        print(f\"Installing {package}...\")\n",
    "        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", package])\n",
    "\n",
    "packages = [\n",
    "    \"requests\",\n",
    "    \"pandas\", \n",
    "    \"rdflib\",\n",
    "    \"sparqlwrapper\",\n",
    "    \"networkx\",\n",
    "    \"matplotlib\",\n",
    "    \"seaborn\",\n",
    "    \"plotly\",\n",
    "    \"ipywidgets\"\n",
    "]\n",
    "\n",
    "for package in packages:\n",
    "    install_if_missing(package)\n",
    "\n",
    "print(\"‚úÖ All dependencies ready\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Core imports\n",
    "import requests\n",
    "import json\n",
    "import pandas as pd\n",
    "from typing import Dict, List, Any, Optional\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import networkx as nx\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "from plotly.subplots import make_subplots\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, HTML, Markdown\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# RDF libraries\n",
    "from rdflib import Graph, Namespace, URIRef, Literal\n",
    "from rdflib.namespace import RDF, RDFS, OWL\n",
    "from SPARQLWrapper import SPARQLWrapper, JSON\n",
    "\n",
    "# Set up plotting\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "print(\"üìä Libraries loaded successfully\")\n",
    "print(f\"üêç Python version: {sys.version}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Knowledge Graph Connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SemanticKnowledgeGraph:\n",
    "    \"\"\"Interface to the semantic knowledge graph with interactive capabilities\"\"\"\n",
    "    \n",
    "    def __init__(self, endpoint_url: str = \"http://localhost:3030/ds/sparql\"):\n",
    "        self.endpoint_url = endpoint_url\n",
    "        self.sparql = SPARQLWrapper(endpoint_url)\n",
    "        self.sparql.setReturnFormat(JSON)\n",
    "        \n",
    "        # Define namespace prefixes\n",
    "        self.prefixes = {\n",
    "            'gist': 'https://w3id.org/semanticarts/ontology/gistCore#',\n",
    "            'bridge': 'https://agentic-data-scraper.com/ontology/gist-dbc-bridge#',\n",
    "            'sow': 'https://agentic-data-scraper.com/ontology/sow#',\n",
    "            'csow': 'https://agentic-data-scraper.com/ontology/complete-sow#',\n",
    "            'rdfs': 'http://www.w3.org/2000/01/rdf-schema#',\n",
    "            'rdf': 'http://www.w3.org/1999/02/22-rdf-syntax-ns#',\n",
    "            'owl': 'http://www.w3.org/2002/07/owl#'\n",
    "        }\n",
    "        \n",
    "        self.prefix_string = '\\n'.join([f'PREFIX {k}: <{v}>' for k, v in self.prefixes.items()])\n",
    "        \n",
    "    def query(self, sparql_query: str) -> pd.DataFrame:\n",
    "        \"\"\"Execute SPARQL query and return results as DataFrame\"\"\"\n",
    "        full_query = f\"{self.prefix_string}\\n\\n{sparql_query}\"\n",
    "        \n",
    "        try:\n",
    "            self.sparql.setQuery(full_query)\n",
    "            results = self.sparql.query().convert()\n",
    "            \n",
    "            if 'results' in results and 'bindings' in results['results']:\n",
    "                bindings = results['results']['bindings']\n",
    "                if not bindings:\n",
    "                    return pd.DataFrame()\n",
    "                \n",
    "                # Convert to DataFrame\n",
    "                data = []\n",
    "                for binding in bindings:\n",
    "                    row = {}\n",
    "                    for var, value in binding.items():\n",
    "                        if value['type'] == 'uri':\n",
    "                            # Simplify URIs by taking the fragment/last part\n",
    "                            row[var] = value['value'].split('#')[-1].split('/')[-1]\n",
    "                            row[f'{var}_full'] = value['value']  # Keep full URI\n",
    "                        else:\n",
    "                            row[var] = value['value']\n",
    "                    data.append(row)\n",
    "                \n",
    "                return pd.DataFrame(data)\n",
    "            \n",
    "            elif 'boolean' in results:\n",
    "                return pd.DataFrame({'result': [results['boolean']]})\n",
    "            \n",
    "            else:\n",
    "                return pd.DataFrame()\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Query error: {e}\")\n",
    "            return pd.DataFrame()\n",
    "    \n",
    "    def test_connection(self) -> bool:\n",
    "        \"\"\"Test connection to the knowledge graph\"\"\"\n",
    "        test_query = \"SELECT (COUNT(*) as ?count) WHERE { ?s ?p ?o }\"\n",
    "        result = self.query(test_query)\n",
    "        \n",
    "        if not result.empty and 'count' in result.columns:\n",
    "            count = int(result['count'].iloc[0])\n",
    "            print(f\"‚úÖ Connected to knowledge graph with {count:,} triples\")\n",
    "            return True\n",
    "        else:\n",
    "            print(\"‚ùå Failed to connect to knowledge graph\")\n",
    "            return False\n",
    "    \n",
    "    def get_statistics(self) -> Dict[str, Any]:\n",
    "        \"\"\"Get basic statistics about the knowledge graph\"\"\"\n",
    "        stats = {}\n",
    "        \n",
    "        # Total triples\n",
    "        total_query = \"SELECT (COUNT(*) as ?count) WHERE { ?s ?p ?o }\"\n",
    "        result = self.query(total_query)\n",
    "        stats['total_triples'] = int(result['count'].iloc[0]) if not result.empty else 0\n",
    "        \n",
    "        # Classes with instance counts\n",
    "        classes_query = \"\"\"\n",
    "        SELECT ?class (COUNT(?instance) as ?count) WHERE {\n",
    "            ?instance a ?class .\n",
    "            FILTER(\n",
    "                STRSTARTS(STR(?class), \"https://w3id.org/semanticarts/ontology/gistCore#\") ||\n",
    "                STRSTARTS(STR(?class), \"https://agentic-data-scraper.com/ontology/\")\n",
    "            )\n",
    "        }\n",
    "        GROUP BY ?class\n",
    "        ORDER BY DESC(?count)\n",
    "        \"\"\"\n",
    "        classes_df = self.query(classes_query)\n",
    "        stats['classes'] = classes_df.to_dict('records') if not classes_df.empty else []\n",
    "        \n",
    "        # Properties\n",
    "        properties_query = \"\"\"\n",
    "        SELECT DISTINCT ?property (COUNT(*) as ?usage) WHERE {\n",
    "            ?s ?property ?o .\n",
    "            FILTER(\n",
    "                STRSTARTS(STR(?property), \"https://agentic-data-scraper.com/ontology/\")\n",
    "            )\n",
    "        }\n",
    "        GROUP BY ?property\n",
    "        ORDER BY DESC(?usage)\n",
    "        \"\"\"\n",
    "        props_df = self.query(properties_query)\n",
    "        stats['properties'] = props_df.to_dict('records') if not props_df.empty else []\n",
    "        \n",
    "        return stats\n",
    "\n",
    "# Initialize connection\n",
    "kg = SemanticKnowledgeGraph()\n",
    "if kg.test_connection():\n",
    "    print(\"üöÄ Ready for semantic experiments!\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è  Make sure Fuseki is running: docker-compose -f docker-compose.semantic.yml up -d\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Knowledge Graph Statistics and Overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get comprehensive statistics\n",
    "stats = kg.get_statistics()\n",
    "\n",
    "print(f\"üìä Knowledge Graph Overview\")\n",
    "print(\"=\" * 40)\n",
    "print(f\"Total Triples: {stats['total_triples']:,}\")\n",
    "print(f\"Classes: {len(stats['classes'])}\")\n",
    "print(f\"Properties: {len(stats['properties'])}\")\n",
    "\n",
    "if stats['classes']:\n",
    "    print(\"\\nüèóÔ∏è  Top Classes by Instance Count:\")\n",
    "    for i, cls in enumerate(stats['classes'][:10]):\n",
    "        print(f\"  {i+1:2d}. {cls['class']:30} {cls['count']:>5} instances\")\n",
    "\n",
    "if stats['properties']:\n",
    "    print(\"\\nüîó Top Properties by Usage:\")\n",
    "    for i, prop in enumerate(stats['properties'][:10]):\n",
    "        print(f\"  {i+1:2d}. {prop['property']:30} {prop['usage']:>5} uses\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize class distribution\n",
    "if stats['classes']:\n",
    "    classes_df = pd.DataFrame(stats['classes'])\n",
    "    \n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))\n",
    "    \n",
    "    # Bar chart of top classes\n",
    "    top_classes = classes_df.head(10)\n",
    "    ax1.barh(top_classes['class'], top_classes['count'].astype(int))\n",
    "    ax1.set_title('Top 10 Classes by Instance Count')\n",
    "    ax1.set_xlabel('Number of Instances')\n",
    "    \n",
    "    # Pie chart of ontology distribution\n",
    "    classes_df['ontology'] = classes_df['class_full'].apply(lambda x: \n",
    "        'Gist' if 'gistCore' in x \n",
    "        else 'DBC Bridge' if 'gist-dbc-bridge' in x\n",
    "        else 'SOW' if 'sow' in x\n",
    "        else 'Complete SOW' if 'complete-sow' in x\n",
    "        else 'Other'\n",
    "    )\n",
    "    \n",
    "    ontology_counts = classes_df.groupby('ontology')['count'].sum().astype(int)\n",
    "    ax2.pie(ontology_counts.values, labels=ontology_counts.index, autopct='%1.1f%%')\n",
    "    ax2.set_title('Instance Distribution by Ontology Level')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"No class data available for visualization\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4-Level Connectivity Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the complete 4-level connectivity chain\n",
    "connectivity_query = \"\"\"\n",
    "SELECT ?org ?canvas ?sow ?contract ?task WHERE {\n",
    "    ?org a gist:Organization .\n",
    "    ?org bridge:hasBusinessModel ?canvas .\n",
    "    ?canvas a bridge:DataBusinessCanvas .\n",
    "    ?canvas bridge:implementedBySOW ?sow .\n",
    "    ?sow a csow:SemanticStatementOfWork .\n",
    "    ?sow bridge:realizesContract ?contract .\n",
    "    ?contract a bridge:DataContract .\n",
    "    ?contract bridge:executedByTask ?task .\n",
    "    ?task a bridge:DataProcessingTask .\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "connectivity_results = kg.query(connectivity_query)\n",
    "\n",
    "print(\"üåâ 4-Level Connectivity Analysis\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "if not connectivity_results.empty:\n",
    "    print(f\"‚úÖ Found {len(connectivity_results)} complete connection(s):\")\n",
    "    print()\n",
    "    for i, row in connectivity_results.iterrows():\n",
    "        print(f\"Connection {i+1}:\")\n",
    "        print(f\"  Level 1 (Gist):        {row['org']}\")\n",
    "        print(f\"  Level 2 (DBC):         {row['canvas']}\")\n",
    "        print(f\"  Level 3 (SOW):         {row['sow']}\")\n",
    "        print(f\"  Level 4 (Contract):    {row['contract']}\")\n",
    "        print(f\"  Level 4 (Task):        {row['task']}\")\n",
    "        print()\n",
    "    \n",
    "    display(connectivity_results)\n",
    "else:\n",
    "    print(\"‚ùå No complete 4-level connections found\")\n",
    "    print(\"This might indicate missing test data or broken semantic links\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze inheritance relationships\n",
    "inheritance_query = \"\"\"\n",
    "SELECT ?subclass ?superclass WHERE {\n",
    "    ?subclass rdfs:subClassOf ?superclass .\n",
    "    FILTER(\n",
    "        STRSTARTS(STR(?subclass), \"https://agentic-data-scraper.com/ontology/\") &&\n",
    "        STRSTARTS(STR(?superclass), \"https://w3id.org/semanticarts/ontology/gistCore#\")\n",
    "    )\n",
    "}\n",
    "ORDER BY ?subclass\n",
    "\"\"\"\n",
    "\n",
    "inheritance_results = kg.query(inheritance_query)\n",
    "\n",
    "print(\"üîó Inheritance Chain Analysis\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "if not inheritance_results.empty:\n",
    "    print(f\"‚úÖ Found {len(inheritance_results)} inheritance relationships:\")\n",
    "    print()\n",
    "    for _, row in inheritance_results.iterrows():\n",
    "        print(f\"  {row['subclass']:35} ‚Üí gist:{row['superclass']}\")\n",
    "    \n",
    "    print(\"\\nüìä Inheritance Summary:\")\n",
    "    gist_parents = inheritance_results.groupby('superclass').size().sort_values(ascending=False)\n",
    "    for parent, count in gist_parents.items():\n",
    "        print(f\"  gist:{parent}: {count} subclasses\")\n",
    "else:\n",
    "    print(\"‚ùå No inheritance relationships found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Business Value Chain Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze business value creation chains\n",
    "value_chain_query = \"\"\"\n",
    "SELECT ?task ?value ?target ?owner WHERE {\n",
    "    ?task a bridge:DataProcessingTask .\n",
    "    ?task bridge:createsBusinessValue ?value .\n",
    "    ?value a bridge:ValueProposition .\n",
    "    \n",
    "    OPTIONAL {\n",
    "        ?canvas bridge:alignsWithTarget ?target .\n",
    "        ?target a bridge:ExecutiveTarget .\n",
    "        ?target bridge:ownedBy ?owner .\n",
    "        ?owner a gist:Person .\n",
    "    }\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "value_results = kg.query(value_chain_query)\n",
    "\n",
    "print(\"üí∞ Business Value Chain Analysis\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "if not value_results.empty:\n",
    "    print(f\"‚úÖ Found {len(value_results)} value creation relationship(s):\")\n",
    "    print()\n",
    "    for i, row in value_results.iterrows():\n",
    "        print(f\"Value Chain {i+1}:\")\n",
    "        print(f\"  Task:              {row['task']}\")\n",
    "        print(f\"  Creates Value:     {row['value']}\")\n",
    "        if pd.notna(row.get('target')):\n",
    "            print(f\"  Executive Target:  {row['target']}\")\n",
    "        if pd.notna(row.get('owner')):\n",
    "            print(f\"  Target Owner:      {row['owner']}\")\n",
    "        print()\n",
    "    \n",
    "    display(value_results)\n",
    "else:\n",
    "    print(\"‚ùå No value creation chains found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interactive SPARQL Query Interface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interactive query widget\n",
    "def create_interactive_query_interface():\n",
    "    # Predefined queries\n",
    "    predefined_queries = {\n",
    "        \"All Classes\": \"\"\"\n",
    "SELECT DISTINCT ?class (COUNT(?instance) as ?count) WHERE {\n",
    "    ?instance a ?class .\n",
    "}\n",
    "GROUP BY ?class\n",
    "ORDER BY DESC(?count)\n",
    "LIMIT 20\"\"\",\n",
    "        \n",
    "        \"Gist Organizations\": \"\"\"\n",
    "SELECT ?org ?label WHERE {\n",
    "    ?org a gist:Organization .\n",
    "    OPTIONAL { ?org rdfs:label ?label }\n",
    "}\"\"\",\n",
    "        \n",
    "        \"Data Assets\": \"\"\"\n",
    "SELECT ?asset ?label ?mapping WHERE {\n",
    "    ?asset a bridge:DataAsset .\n",
    "    OPTIONAL { ?asset rdfs:label ?label }\n",
    "    OPTIONAL { ?asset bridge:hasSemanticMapping ?mapping }\n",
    "}\"\"\",\n",
    "        \n",
    "        \"SOW Contracts\": \"\"\"\n",
    "SELECT ?sow ?challenge ?outcome WHERE {\n",
    "    ?sow a csow:SemanticStatementOfWork .\n",
    "    OPTIONAL { ?sow csow:hasBusinessChallenge ?challenge }\n",
    "    OPTIONAL { ?sow csow:hasDesiredOutcome ?outcome }\n",
    "}\"\"\",\n",
    "        \n",
    "        \"Property Usage\": \"\"\"\n",
    "SELECT ?property (COUNT(*) as ?usage) WHERE {\n",
    "    ?s ?property ?o .\n",
    "    FILTER(STRSTARTS(STR(?property), \"https://agentic-data-scraper.com/ontology/\"))\n",
    "}\n",
    "GROUP BY ?property\n",
    "ORDER BY DESC(?usage)\"\"\"\n",
    "    }\n",
    "    \n",
    "    # Widget setup\n",
    "    query_dropdown = widgets.Dropdown(\n",
    "        options=list(predefined_queries.keys()),\n",
    "        value=list(predefined_queries.keys())[0],\n",
    "        description='Query:',\n",
    "        style={'description_width': 'initial'}\n",
    "    )\n",
    "    \n",
    "    query_text = widgets.Textarea(\n",
    "        value=predefined_queries[query_dropdown.value],\n",
    "        placeholder='Enter your SPARQL query here...',\n",
    "        description='SPARQL:',\n",
    "        style={'description_width': 'initial'},\n",
    "        layout=widgets.Layout(width='100%', height='200px')\n",
    "    )\n",
    "    \n",
    "    execute_button = widgets.Button(\n",
    "        description='Execute Query',\n",
    "        button_style='primary',\n",
    "        icon='play'\n",
    "    )\n",
    "    \n",
    "    output_area = widgets.Output()\n",
    "    \n",
    "    def update_query(change):\n",
    "        query_text.value = predefined_queries[change['new']]\n",
    "    \n",
    "    def execute_query(button):\n",
    "        with output_area:\n",
    "            output_area.clear_output()\n",
    "            print(f\"üîç Executing query: {query_dropdown.value}\")\n",
    "            print(\"=\" * 50)\n",
    "            \n",
    "            try:\n",
    "                result = kg.query(query_text.value)\n",
    "                \n",
    "                if result.empty:\n",
    "                    print(\"No results found\")\n",
    "                else:\n",
    "                    print(f\"‚úÖ Found {len(result)} result(s)\")\n",
    "                    display(result)\n",
    "                    \n",
    "                    # Show basic statistics if numeric columns exist\n",
    "                    numeric_cols = result.select_dtypes(include=['int64', 'float64']).columns\n",
    "                    if len(numeric_cols) > 0:\n",
    "                        print(\"\\nüìä Numeric Summary:\")\n",
    "                        display(result[numeric_cols].describe())\n",
    "                        \n",
    "            except Exception as e:\n",
    "                print(f\"‚ùå Query error: {e}\")\n",
    "    \n",
    "    query_dropdown.observe(update_query, names='value')\n",
    "    execute_button.on_click(execute_query)\n",
    "    \n",
    "    # Layout\n",
    "    interface = widgets.VBox([\n",
    "        widgets.HTML(\"<h3>üîç Interactive SPARQL Query Interface</h3>\"),\n",
    "        query_dropdown,\n",
    "        query_text,\n",
    "        execute_button,\n",
    "        output_area\n",
    "    ])\n",
    "    \n",
    "    return interface\n",
    "\n",
    "# Create and display the interface\n",
    "query_interface = create_interactive_query_interface()\n",
    "display(query_interface)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Knowledge Graph Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_knowledge_graph_visualization():\n",
    "    \"\"\"Create an interactive network visualization of the knowledge graph\"\"\"\n",
    "    \n",
    "    # Query for relationships\n",
    "    relationships_query = \"\"\"\n",
    "    SELECT ?subject ?predicate ?object WHERE {\n",
    "        ?subject ?predicate ?object .\n",
    "        FILTER(\n",
    "            STRSTARTS(STR(?predicate), \"https://agentic-data-scraper.com/ontology/\") &&\n",
    "            isURI(?object)\n",
    "        )\n",
    "    }\n",
    "    LIMIT 50\n",
    "    \"\"\"\n",
    "    \n",
    "    relationships = kg.query(relationships_query)\n",
    "    \n",
    "    if relationships.empty:\n",
    "        print(\"‚ùå No relationships found for visualization\")\n",
    "        return\n",
    "    \n",
    "    # Create NetworkX graph\n",
    "    G = nx.DiGraph()\n",
    "    \n",
    "    # Add nodes and edges\n",
    "    for _, row in relationships.iterrows():\n",
    "        subject = row['subject']\n",
    "        predicate = row['predicate']\n",
    "        obj = row['object']\n",
    "        \n",
    "        G.add_edge(subject, obj, label=predicate)\n",
    "    \n",
    "    # Create layout\n",
    "    pos = nx.spring_layout(G, k=3, iterations=50)\n",
    "    \n",
    "    # Prepare data for Plotly\n",
    "    edge_x = []\n",
    "    edge_y = []\n",
    "    edge_info = []\n",
    "    \n",
    "    for edge in G.edges(data=True):\n",
    "        x0, y0 = pos[edge[0]]\n",
    "        x1, y1 = pos[edge[1]]\n",
    "        edge_x.extend([x0, x1, None])\n",
    "        edge_y.extend([y0, y1, None])\n",
    "        edge_info.append(edge[2]['label'])\n",
    "    \n",
    "    edge_trace = go.Scatter(\n",
    "        x=edge_x, y=edge_y,\n",
    "        line=dict(width=0.5, color='#888'),\n",
    "        hoverinfo='none',\n",
    "        mode='lines'\n",
    "    )\n",
    "    \n",
    "    node_x = []\n",
    "    node_y = []\n",
    "    node_text = []\n",
    "    node_colors = []\n",
    "    \n",
    "    for node in G.nodes():\n",
    "        x, y = pos[node]\n",
    "        node_x.append(x)\n",
    "        node_y.append(y)\n",
    "        node_text.append(node)\n",
    "        \n",
    "        # Color nodes by ontology level\n",
    "        if 'gistCore' in node:\n",
    "            node_colors.append('red')  # Level 1: Gist\n",
    "        elif 'gist-dbc-bridge' in node:\n",
    "            node_colors.append('blue')  # Level 2: DBC\n",
    "        elif 'sow' in node:\n",
    "            node_colors.append('green')  # Level 3: SOW\n",
    "        else:\n",
    "            node_colors.append('orange')  # Other\n",
    "    \n",
    "    node_trace = go.Scatter(\n",
    "        x=node_x, y=node_y,\n",
    "        mode='markers+text',\n",
    "        hoverinfo='text',\n",
    "        text=node_text,\n",
    "        textposition=\"middle center\",\n",
    "        marker=dict(\n",
    "            showscale=False,\n",
    "            color=node_colors,\n",
    "            size=10,\n",
    "            line=dict(width=2)\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    # Create figure\n",
    "    fig = go.Figure(\n",
    "        data=[edge_trace, node_trace],\n",
    "        layout=go.Layout(\n",
    "            title='üåê Knowledge Graph Visualization',\n",
    "            titlefont_size=16,\n",
    "            showlegend=False,\n",
    "            hovermode='closest',\n",
    "            margin=dict(b=20,l=5,r=5,t=40),\n",
    "            annotations=[\n",
    "                dict(\n",
    "                    text=\"Colors: Red=Gist, Blue=DBC Bridge, Green=SOW, Orange=Other\",\n",
    "                    showarrow=False,\n",
    "                    xref=\"paper\", yref=\"paper\",\n",
    "                    x=0.005, y=-0.002,\n",
    "                    xanchor=\"left\", yanchor=\"bottom\",\n",
    "                    font=dict(size=12)\n",
    "                )\n",
    "            ],\n",
    "            xaxis=dict(showgrid=False, zeroline=False, showticklabels=False),\n",
    "            yaxis=dict(showgrid=False, zeroline=False, showticklabels=False)\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    fig.show()\n",
    "    \n",
    "    print(f\"üìä Visualization Statistics:\")\n",
    "    print(f\"  Nodes: {len(G.nodes())}\")\n",
    "    print(f\"  Edges: {len(G.edges())}\")\n",
    "    print(f\"  Density: {nx.density(G):.3f}\")\n",
    "\n",
    "# Create visualization\n",
    "create_knowledge_graph_visualization()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Semantic Reasoning Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test semantic reasoning capabilities\n",
    "def test_semantic_reasoning():\n",
    "    \"\"\"Test various semantic reasoning queries\"\"\"\n",
    "    \n",
    "    reasoning_tests = {\n",
    "        \"Transitive Relationships\": \"\"\"\n",
    "        SELECT ?org ?task WHERE {\n",
    "            ?org a gist:Organization .\n",
    "            ?org bridge:hasBusinessModel ?canvas .\n",
    "            ?canvas bridge:implementedBySOW ?sow .\n",
    "            ?sow bridge:realizesContract ?contract .\n",
    "            ?contract bridge:executedByTask ?task .\n",
    "            # This shows transitive relationship: org -> canvas -> sow -> contract -> task\n",
    "        }\"\"\",\n",
    "        \n",
    "        \"Class Hierarchy\": \"\"\"\n",
    "        SELECT ?instance ?specificType ?generalType WHERE {\n",
    "            ?instance a ?specificType .\n",
    "            ?specificType rdfs:subClassOf ?generalType .\n",
    "            FILTER(STRSTARTS(STR(?generalType), \"https://w3id.org/semanticarts/ontology/gistCore#\"))\n",
    "        }\"\"\",\n",
    "        \n",
    "        \"Inverse Relationships\": \"\"\"\n",
    "        SELECT ?value ?task WHERE {\n",
    "            ?task bridge:createsBusinessValue ?value .\n",
    "            # Find what creates specific business values\n",
    "        }\"\"\",\n",
    "        \n",
    "        \"Multi-hop Connections\": \"\"\"\n",
    "        SELECT ?start ?end (COUNT(?intermediate) as ?hops) WHERE {\n",
    "            ?start a gist:Organization .\n",
    "            ?start ?p1 ?intermediate .\n",
    "            ?intermediate ?p2 ?end .\n",
    "            ?end a bridge:DataProcessingTask .\n",
    "        }\n",
    "        GROUP BY ?start ?end\n",
    "        \"\"\"\n",
    "    }\n",
    "    \n",
    "    print(\"üß† Semantic Reasoning Tests\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    for test_name, query in reasoning_tests.items():\n",
    "        print(f\"\\nüîç {test_name}:\")\n",
    "        result = kg.query(query)\n",
    "        \n",
    "        if not result.empty:\n",
    "            print(f\"  ‚úÖ Found {len(result)} result(s)\")\n",
    "            if len(result) <= 5:  # Show results if few enough\n",
    "                display(result)\n",
    "            else:\n",
    "                print(f\"  üìä Sample results:\")\n",
    "                display(result.head())\n",
    "        else:\n",
    "            print(f\"  ‚ùå No results found\")\n",
    "\n",
    "test_semantic_reasoning()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom Query Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experiment area - modify this cell for your custom queries\n",
    "\n",
    "# Example: Find all data assets and their semantic mappings\n",
    "custom_query = \"\"\"\n",
    "SELECT ?asset ?label ?concept ?preferredLabel WHERE {\n",
    "    ?asset a bridge:DataAsset .\n",
    "    OPTIONAL { ?asset rdfs:label ?label }\n",
    "    OPTIONAL { \n",
    "        ?asset bridge:hasSemanticMapping ?concept .\n",
    "        ?concept bridge:hasPreferredLabel ?preferredLabel \n",
    "    }\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "print(\"üß™ Custom Query Experiment\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "result = kg.query(custom_query)\n",
    "\n",
    "if not result.empty:\n",
    "    print(f\"‚úÖ Found {len(result)} result(s)\")\n",
    "    display(result)\n",
    "else:\n",
    "    print(\"‚ùå No results found\")\n",
    "\n",
    "# Add your own experiments below this line\n",
    "# ================================================\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def benchmark_queries():\n",
    "    \"\"\"Benchmark different types of queries for performance analysis\"\"\"\n",
    "    \n",
    "    benchmark_queries = {\n",
    "        \"Simple Count\": \"SELECT (COUNT(*) as ?count) WHERE { ?s ?p ?o }\",\n",
    "        \"Class Instances\": \"SELECT * WHERE { ?s a ?type } LIMIT 100\",\n",
    "        \"Property Patterns\": \"SELECT * WHERE { ?s bridge:hasBusinessModel ?o } LIMIT 10\",\n",
    "        \"Complex Join\": \"\"\"\n",
    "        SELECT ?org ?canvas ?sow WHERE {\n",
    "            ?org a gist:Organization .\n",
    "            ?org bridge:hasBusinessModel ?canvas .\n",
    "            ?canvas bridge:implementedBySOW ?sow .\n",
    "        }\"\"\",\n",
    "        \"Inheritance Query\": \"\"\"\n",
    "        SELECT ?sub ?super WHERE {\n",
    "            ?sub rdfs:subClassOf ?super .\n",
    "        } LIMIT 20\"\"\"\n",
    "    }\n",
    "    \n",
    "    print(\"‚ö° Query Performance Benchmark\")\n",
    "    print(\"=\" * 40)\n",
    "    \n",
    "    performance_results = []\n",
    "    \n",
    "    for query_name, query in benchmark_queries.items():\n",
    "        # Run query multiple times for average\n",
    "        times = []\n",
    "        for _ in range(3):\n",
    "            start_time = time.time()\n",
    "            result = kg.query(query)\n",
    "            end_time = time.time()\n",
    "            times.append(end_time - start_time)\n",
    "        \n",
    "        avg_time = sum(times) / len(times)\n",
    "        result_count = len(result) if not result.empty else 0\n",
    "        \n",
    "        performance_results.append({\n",
    "            'Query': query_name,\n",
    "            'Avg Time (s)': f\"{avg_time:.4f}\",\n",
    "            'Results': result_count\n",
    "        })\n",
    "        \n",
    "        print(f\"  {query_name:20} {avg_time:.4f}s ({result_count} results)\")\n",
    "    \n",
    "    # Create performance DataFrame\n",
    "    perf_df = pd.DataFrame(performance_results)\n",
    "    \n",
    "    # Visualize performance\n",
    "    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "    times_float = [float(t) for t in perf_df['Avg Time (s)']]\n",
    "    bars = ax.bar(perf_df['Query'], times_float)\n",
    "    ax.set_title('Query Performance Comparison')\n",
    "    ax.set_ylabel('Average Time (seconds)')\n",
    "    ax.set_xlabel('Query Type')\n",
    "    plt.xticks(rotation=45, ha='right')\n",
    "    \n",
    "    # Add value labels on bars\n",
    "    for bar, time_val in zip(bars, times_float):\n",
    "        height = bar.get_height()\n",
    "        ax.text(bar.get_x() + bar.get_width()/2., height + 0.001,\n",
    "                f'{time_val:.4f}s', ha='center', va='bottom')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    return perf_df\n",
    "\n",
    "performance_data = benchmark_queries()\n",
    "display(performance_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export and Save Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export functionality for sharing results\n",
    "def export_results():\n",
    "    \"\"\"Export key results for sharing or reporting\"\"\"\n",
    "    \n",
    "    # Get comprehensive data\n",
    "    export_data = {\n",
    "        'statistics': kg.get_statistics(),\n",
    "        'connectivity': kg.query(\"\"\"\n",
    "        SELECT ?org ?canvas ?sow ?contract ?task WHERE {\n",
    "            ?org a gist:Organization .\n",
    "            ?org bridge:hasBusinessModel ?canvas .\n",
    "            ?canvas bridge:implementedBySOW ?sow .\n",
    "            ?sow bridge:realizesContract ?contract .\n",
    "            ?contract bridge:executedByTask ?task .\n",
    "        }\"\"\").to_dict('records'),\n",
    "        'inheritance': kg.query(\"\"\"\n",
    "        SELECT ?subclass ?superclass WHERE {\n",
    "            ?subclass rdfs:subClassOf ?superclass .\n",
    "            FILTER(\n",
    "                STRSTARTS(STR(?subclass), \"https://agentic-data-scraper.com/ontology/\") &&\n",
    "                STRSTARTS(STR(?superclass), \"https://w3id.org/semanticarts/ontology/gistCore#\")\n",
    "            )\n",
    "        }\"\"\").to_dict('records'),\n",
    "        'value_chains': kg.query(\"\"\"\n",
    "        SELECT ?task ?value ?target ?owner WHERE {\n",
    "            ?task a bridge:DataProcessingTask .\n",
    "            ?task bridge:createsBusinessValue ?value .\n",
    "            ?value a bridge:ValueProposition .\n",
    "            OPTIONAL {\n",
    "                ?canvas bridge:alignsWithTarget ?target .\n",
    "                ?target bridge:ownedBy ?owner .\n",
    "            }\n",
    "        }\"\"\").to_dict('records')\n",
    "    }\n",
    "    \n",
    "    # Save to JSON\n",
    "    import json\n",
    "    with open('../../data/semantic_analysis_results.json', 'w') as f:\n",
    "        json.dump(export_data, f, indent=2, default=str)\n",
    "    \n",
    "    print(\"‚úÖ Results exported to data/semantic_analysis_results.json\")\n",
    "    \n",
    "    # Create summary report\n",
    "    summary = f\"\"\"\n",
    "# Semantic Knowledge Graph Analysis Summary\n",
    "\n",
    "## Statistics\n",
    "- **Total Triples**: {export_data['statistics']['total_triples']:,}\n",
    "- **Classes**: {len(export_data['statistics']['classes'])}\n",
    "- **Properties**: {len(export_data['statistics']['properties'])}\n",
    "\n",
    "## Connectivity\n",
    "- **4-Level Connections**: {len(export_data['connectivity'])}\n",
    "- **Inheritance Relationships**: {len(export_data['inheritance'])}\n",
    "- **Value Chains**: {len(export_data['value_chains'])}\n",
    "\n",
    "## Status\n",
    "‚úÖ Semantic infrastructure is operational and ready for applications\n",
    "\"\"\"\n",
    "    \n",
    "    with open('../../data/semantic_summary.md', 'w') as f:\n",
    "        f.write(summary)\n",
    "    \n",
    "    print(\"‚úÖ Summary report saved to data/semantic_summary.md\")\n",
    "    \n",
    "    return export_data\n",
    "\n",
    "# Export results\n",
    "exported_data = export_results()\n",
    "print(\"\\nüìã Export Complete - Data ready for sharing or further analysis\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next Steps and Experimentation Ideas\n",
    "\n",
    "This notebook provides a comprehensive foundation for experimenting with the semantic knowledge graph. Here are some ideas for further exploration:\n",
    "\n",
    "### üî¨ **Experiment Ideas**\n",
    "1. **Add New Ontology Classes**: Extend the ontologies with domain-specific classes\n",
    "2. **Create Complex Queries**: Build multi-hop reasoning queries\n",
    "3. **Visualization Enhancements**: Create specialized visualizations for different aspects\n",
    "4. **Performance Optimization**: Test query optimization strategies\n",
    "5. **Data Integration**: Load real business data and map it to the ontologies\n",
    "\n",
    "### üöÄ **Application Development**\n",
    "1. **Semantic Search**: Build search interfaces using the knowledge graph\n",
    "2. **Business Intelligence**: Create dashboards based on semantic queries\n",
    "3. **Automated Reasoning**: Implement inference rules for business logic\n",
    "4. **Data Quality**: Use semantic constraints for data validation\n",
    "5. **Integration APIs**: Build REST APIs over the semantic layer\n",
    "\n",
    "### üìä **Analytics and Insights**\n",
    "1. **Graph Analytics**: Use NetworkX for advanced graph analysis\n",
    "2. **Pattern Discovery**: Find interesting patterns in the semantic data\n",
    "3. **Anomaly Detection**: Identify semantic inconsistencies\n",
    "4. **Recommendation Systems**: Build recommendations using semantic similarity\n",
    "5. **Predictive Models**: Create ML models using semantic features\n",
    "\n",
    "---\n",
    "\n",
    "**Happy experimenting! üéâ**\n",
    "\n",
    "The semantic infrastructure is now ready for building sophisticated knowledge-driven applications."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}