{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# üéØ ET(K)L Formal Governance Chain: Where This Work Fits\n",
        "\n",
        "## The Four-Layer ET(K)L Architecture\n",
        "\n",
        "This semantic foundation work enables the **formal governance chain** that makes ET(K)L transformational:\n",
        "\n",
        "\n",
        "\n",
        "### Semantic Foundation as Connective Tissue\n",
        "\n",
        "What you'll build in this notebook serves as the **semantic connective tissue** that:\n",
        "\n",
        "- **Links Executive Targets to Technical Implementation**: Formal ontologies ensure business intent is preserved through all transformation layers\n",
        "- **Enables Automated Governance**: Semantic rules make business policies machine-readable and enforceable\n",
        "- **Supports Knowledge-Driven Agents**: AI agents can understand business context through formal semantic relationships\n",
        "- **Provides Formal Value Traceability**: Every technical decision can be traced back to business value through semantic graphs\n",
        "\n",
        "### From Interpretation to Provability\n",
        "\n",
        "Traditional data projects rely on **interpretation** of business value. ET(K)L enables **provable** business value through formal semantic chains:\n",
        "\n",
        "- **Instead of**: \"This dashboard probably helps with decision-making\"\n",
        "- **ET(K)L provides**: \"This semantic relationship formally connects Executive Target A to Metric B via SOW requirement C\"\n",
        "\n",
        "---\n",
        "\n",
        "**Next**: Let's build the semantic infrastructure that makes this formal governance chain possible.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# üíº Business Motivation: Why Semantic Foundations Matter\n",
        "\n",
        "## Real-World Challenge: European Energy Trading Optimization\n",
        "\n",
        "Before diving into technical implementation, let's understand **why** this semantic foundation work is critical for modern enterprises.\n",
        "\n",
        "### The Business Problem\n",
        "\n",
        "**EuroEnergy Trading Solutions** needed to optimize renewable energy trading recommendations across complex European markets. Traditional data approaches failed because:\n",
        "\n",
        "- **Fragmented Data Sources**: Market data, regulatory requirements, and trading rules existed in silos\n",
        "- **Context Loss**: Business rules were hardcoded in queries, making them brittle and hard to maintain  \n",
        "- **Compliance Complexity**: European energy regulations required formal traceability that spreadsheets couldn't provide\n",
        "- **Decision Latency**: Analysts spent more time gathering data than making strategic decisions\n",
        "\n",
        "### The ET(K)L Transformation\n",
        "\n",
        "By building semantic foundations first, EuroEnergy achieved:\n",
        "\n",
        "- **Unified Knowledge Model**: All trading rules, market data, and regulations represented as connected semantic concepts\n",
        "- **Automated Compliance**: Regulatory requirements became machine-readable constraints  \n",
        "- **Intelligent Insights**: AI agents could reason about trading opportunities using business context\n",
        "- **Provable Decisions**: Every trading recommendation traced back to formal business rules and market conditions\n",
        "\n",
        "### What You'll Learn to Build\n",
        "\n",
        "This notebook will show you how to create the **semantic infrastructure** that made this transformation possible:\n",
        "\n",
        "1. **Semantic Ontologies**: Formal models of business concepts and relationships\n",
        "2. **Knowledge Graphs**: Connected data that preserves business meaning  \n",
        "3. **SPARQL Reasoning**: Queries that understand business context, not just data structure\n",
        "4. **Governance Integration**: Technical implementation that enforces business rules\n",
        "\n",
        "---\n",
        "\n",
        "**The Foundation Comes First**: Without proper semantic infrastructure, even the most sophisticated AI agents and data pipelines will struggle with context and meaning. Let's build that foundation."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# üèóÔ∏è What We'll Build: Your ET(K)L Semantic Foundation\n",
        "\n",
        "## The Technical Journey: From Business Need to Semantic Infrastructure\n",
        "\n",
        "Now that you understand the business imperative, let's map out exactly what we'll build to create this semantic foundation.\n",
        "\n",
        "### üéØ Learning Journey Overview\n",
        "\n",
        "**Phase 1: Semantic Concepts**\n",
        "- Build formal ontologies that capture business concepts (not just data schemas)\n",
        "- Create reusable semantic models that grow with your organization\n",
        "- Establish the vocabulary that enables knowledge-driven transformation\n",
        "\n",
        "**Phase 2: Knowledge Graphs**  \n",
        "- Transform business data into connected knowledge\n",
        "- Preserve context and meaning through semantic relationships\n",
        "- Enable reasoning and inference over business concepts\n",
        "\n",
        "**Phase 3: Business-Aware Querying**\n",
        "- Write SPARQL queries that understand business context\n",
        "- Demonstrate how semantic queries differ from SQL data extraction\n",
        "- Show formal traceability from query results to business outcomes\n",
        "\n",
        "**Phase 4: ET(K)L Integration**\n",
        "- Connect semantic foundation to governance chains\n",
        "- Enable automated business rule enforcement\n",
        "- Prepare foundation for AI agent integration\n",
        "\n",
        "### üîó ET(K)L Connection Points\n",
        "\n",
        "Each technical component directly supports ET(K)L principles:\n",
        "\n",
        "| Technical Component | ET(K)L Principle | Business Impact |\n",
        "|-------------------|-----------------|----------------|\n",
        "| **Formal Ontologies** | Knowledge as Input | Business concepts shape data transformation |\n",
        "| **Semantic Relationships** | Semantics over Strings | Reusable logic across domains and teams |\n",
        "| **Context-Aware Queries** | Enterprise Alignment | Technical queries serve business outcomes |\n",
        "| **Modular Vocabularies** | Composable Architecture | Knowledge modules portable across projects |\n",
        "| **Business-Rule Integration** | Sociotechnical Evolution | Teams collaborate using shared semantic language |\n",
        "\n",
        "---\n",
        "\n",
        "**Ready to Build?** Let's start with environment setup, then dive into creating semantic infrastructure that transforms how your organization handles knowledge.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üî¨ Testing core functionality after uv migration...\n",
            "‚úÖ All imports successful\n",
            "‚ùå SemanticKnowledgeGraph not defined - run connection cell first\n",
            "‚úÖ NetworkX working - test graph has 2 nodes\n",
            "‚úÖ Plotly working - test figure created\n",
            "\n",
            "üéØ Environment verification complete!\n",
            "üí° If all tests pass, the notebook is ready for semantic experiments.\n"
          ]
        }
      ],
      "source": [
        "# üß™ Quick Environment Verification Test\n",
        "print(\"üî¨ Testing core functionality after uv migration...\")\n",
        "\n",
        "# Test 1: Basic imports\n",
        "try:\n",
        "    import pandas as pd\n",
        "    import networkx as nx\n",
        "    import plotly.graph_objects as go\n",
        "    from SPARQLWrapper import SPARQLWrapper, JSON\n",
        "    print(\"‚úÖ All imports successful\")\n",
        "except ImportError as e:\n",
        "    print(f\"‚ùå Import failed: {e}\")\n",
        "\n",
        "# Test 2: SemanticKnowledgeGraph instantiation  \n",
        "try:\n",
        "    test_kg = SemanticKnowledgeGraph()\n",
        "    print(\"‚úÖ SemanticKnowledgeGraph class available\")\n",
        "except NameError:\n",
        "    print(\"‚ùå SemanticKnowledgeGraph not defined - run connection cell first\")\n",
        "\n",
        "# Test 3: Simple NetworkX graph\n",
        "try:\n",
        "    test_graph = nx.Graph()\n",
        "    test_graph.add_edge('A', 'B')\n",
        "    print(f\"‚úÖ NetworkX working - test graph has {len(test_graph.nodes())} nodes\")\n",
        "except Exception as e:\n",
        "    print(f\"‚ùå NetworkX failed: {e}\")\n",
        "\n",
        "# Test 4: Simple Plotly figure\n",
        "try:\n",
        "    test_fig = go.Figure(data=go.Scatter(x=[1,2,3], y=[4,5,6]))\n",
        "    print(\"‚úÖ Plotly working - test figure created\")\n",
        "except Exception as e:\n",
        "    print(f\"‚ùå Plotly failed: {e}\")\n",
        "\n",
        "print(\"\\nüéØ Environment verification complete!\")\n",
        "print(\"üí° If all tests pass, the notebook is ready for semantic experiments.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## ‚úÖ Environment Verification Test\n",
        "\n",
        "**Quick test to verify all components are working correctly after the uv migration.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### üî¨ Environment Verification\n",
        "\n",
        "**What this does:** This cell performs a quick test to verify our development environment is working correctly after migrating from pip to uv dependency management.\n",
        "\n",
        "**Why it's important:** In the AGENTIC-DATA-SCRAPER platform, we use semantic knowledge graphs to understand and process business data. Before we can work with complex ontologies, we need to ensure all our Python packages are properly installed and accessible.\n",
        "\n",
        "**Key concepts:**\n",
        "- **Import testing**: Verifying that essential packages (pandas, networkx, plotly, etc.) are available\n",
        "- **Class instantiation**: Checking that our custom SemanticKnowledgeGraph class is ready\n",
        "- **Environment validation**: Making sure our development setup works before complex operations\n",
        "\n",
        "**What to expect:** You should see green checkmarks (‚úÖ) for each test if everything is working correctly."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Setup and Dependencies"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### üì¶ Dependency Management with uv\n",
        "\n",
        "**What this does:** This cell verifies that our project dependencies are properly managed using uv (a fast Python package manager) instead of the traditional pip approach.\n",
        "\n",
        "**Why we use uv:** The AGENTIC-DATA-SCRAPER platform requires many specialized packages for semantic processing (like rdflib, SPARQLWrapper, networkx). Traditional pip can be slow and sometimes creates conflicts. uv provides:\n",
        "- **Faster installation**: 10-100x faster than pip\n",
        "- **Better dependency resolution**: Prevents version conflicts\n",
        "- **Reproducible environments**: Ensures everyone has the same package versions\n",
        "\n",
        "**Key packages we're testing:**\n",
        "- **SPARQLWrapper**: For querying semantic knowledge graphs\n",
        "- **rdflib**: For working with RDF (Resource Description Framework) data\n",
        "- **pandas**: For data manipulation and analysis\n",
        "- **networkx**: For graph analysis and visualization\n",
        "- **plotly**: For interactive data visualization\n",
        "\n",
        "**What to expect:** Green checkmarks mean all our semantic processing tools are ready to use."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ‚úÖ Dependencies are managed by uv - no installation needed\n",
        "# All required packages are already specified in pyproject.toml:\n",
        "# - sparqlwrapper>=2.0.0\n",
        "# - rdflib>=7.0.0  \n",
        "# - pandas>=2.2.0\n",
        "# - networkx (via other dependencies)\n",
        "# - plotly (may need to be added)\n",
        "# - matplotlib, seaborn, ipywidgets\n",
        "\n",
        "print(\"‚úÖ Using uv-managed dependencies from pyproject.toml\")\n",
        "\n",
        "# Import test to verify key packages are available\n",
        "try:\n",
        "    import pandas as pd\n",
        "    import requests\n",
        "    import rdflib\n",
        "    from SPARQLWrapper import SPARQLWrapper, JSON\n",
        "    print(\"‚úÖ Core semantic packages available\")\n",
        "except ImportError as e:\n",
        "    print(f\"‚ùå Missing package: {e}\")\n",
        "    print(\"üí° Run: uv sync\")\n",
        "\n",
        "try:\n",
        "    import networkx as nx\n",
        "    import matplotlib.pyplot as plt\n",
        "    print(\"‚úÖ Visualization packages available\")\n",
        "except ImportError as e:\n",
        "    print(f\"‚ùå Missing visualization package: {e}\")\n",
        "    print(\"üí° May need: uv add networkx matplotlib\")\n",
        "\n",
        "try:\n",
        "    import plotly.graph_objects as go\n",
        "    import seaborn as sns\n",
        "    import ipywidgets as widgets\n",
        "    print(\"‚úÖ Advanced visualization packages available\")\n",
        "except ImportError as e:\n",
        "    print(f\"‚ùå Missing advanced package: {e}\")\n",
        "    print(\"üí° May need: uv add plotly seaborn ipywidgets\")\n",
        "\n",
        "print(\"‚úÖ Dependency check complete\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### üåê Semantic Knowledge Graph Connection Class\n",
        "\n",
        "**What this does:** This cell defines our main `SemanticKnowledgeGraph` class - the core interface for communicating with our semantic knowledge graph database.\n",
        "\n",
        "**Understanding semantic knowledge graphs:**\n",
        "A semantic knowledge graph is like a smart database that understands relationships between concepts. Instead of just storing data in tables, it stores knowledge as interconnected concepts with meaningful relationships.\n",
        "\n",
        "**Key components of our class:**\n",
        "\n",
        "**1. SPARQL Endpoint Connection:**\n",
        "- **SPARQL** is like SQL but for graph databases\n",
        "- Our knowledge graph runs on Apache Jena Fuseki (a graph database server)\n",
        "- The endpoint URL (`http://localhost:3030/ds/sparql`) is where we send queries\n",
        "\n",
        "**2. Namespace Prefixes:**\n",
        "Think of these as shortcuts for long web addresses:\n",
        "- `gist:` = Core business concepts (organizations, people, etc.)\n",
        "- `bridge:` = Connections between business strategy and technical implementation\n",
        "- `sow:` = Statement of Work contracts\n",
        "- `rdfs:` & `owl:` = Standard semantic web vocabularies\n",
        "\n",
        "**3. Query Method:**\n",
        "- Sends SPARQL queries to the knowledge graph\n",
        "- Converts results to pandas DataFrames (familiar table format)\n",
        "- Automatically simplifies long URIs to readable names\n",
        "\n",
        "**Why this matters:** This class is how our AGENTIC-DATA-SCRAPER platform reads business requirements from the semantic knowledge graph and understands how to generate appropriate data processing code.\n",
        "\n",
        "**What to expect:** A connection test showing how many triples (facts) are in our knowledge graph."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Core imports\n",
        "import requests\n",
        "import json\n",
        "import pandas as pd\n",
        "from typing import Dict, List, Any, Optional\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import networkx as nx\n",
        "import plotly.graph_objects as go\n",
        "import plotly.express as px\n",
        "from plotly.subplots import make_subplots\n",
        "import ipywidgets as widgets\n",
        "from IPython.display import display, HTML, Markdown\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# RDF libraries\n",
        "from rdflib import Graph, Namespace, URIRef, Literal\n",
        "from rdflib.namespace import RDF, RDFS, OWL\n",
        "from SPARQLWrapper import SPARQLWrapper, JSON\n",
        "\n",
        "# Set up plotting\n",
        "plt.style.use('default')  # Updated for broader compatibility\n",
        "sns.set_palette(\"husl\")\n",
        "\n",
        "print(\"üìä Libraries loaded successfully\")\n",
        "print(f\"üêç Python version: {__import__('sys').version}\")\n",
        "print(f\"üì¶ Environment: uv-managed dependencies\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### üìä Knowledge Graph Statistics & Analysis\n",
        "\n",
        "**What this does:** This cell analyzes our semantic knowledge graph to understand what data we have and how it's organized.\n",
        "\n",
        "**Understanding the metrics:**\n",
        "\n",
        "**1. Total Triples:**\n",
        "- A \"triple\" is a basic fact in semantic format: Subject-Predicate-Object\n",
        "- Example: \"CompanyA hasBusinessModel DataStrategy\" \n",
        "- More triples = more detailed knowledge\n",
        "\n",
        "**2. Classes (Types of Things):**\n",
        "- Classes define what types of entities exist (like Organization, Contract, Task)\n",
        "- Instance counts show how many real examples we have of each class\n",
        "- This helps us understand our data coverage\n",
        "\n",
        "**3. Properties (Types of Relationships):**\n",
        "- Properties connect entities with meaningful relationships\n",
        "- Usage counts show which relationships are most common\n",
        "- Helps identify the main patterns in our business data\n",
        "\n",
        "**Why this analysis matters:**\n",
        "In the AGENTIC-DATA-SCRAPER platform, we need to understand the scope and completeness of our semantic data before generating code. This analysis tells us:\n",
        "- What business concepts are available\n",
        "- How detailed our knowledge is\n",
        "- Which relationships are most important for code generation\n",
        "\n",
        "**What to expect:** Summary statistics showing the scale of our semantic knowledge graph, plus lists of the most common classes and properties."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### üìà Data Visualization & Distribution Analysis\n",
        "\n",
        "**What this does:** This cell creates visual charts to help us understand the structure and distribution of our semantic knowledge graph data.\n",
        "\n",
        "**Understanding the visualizations:**\n",
        "\n",
        "**1. Bar Chart - Top Classes by Instance Count:**\n",
        "- Shows which types of business entities we have the most data about\n",
        "- Helps identify where our knowledge graph is strongest\n",
        "- Example: If \"DataProcessingTask\" has 50 instances, we have lots of task data\n",
        "\n",
        "**2. Pie Chart - Instance Distribution by Ontology Level:**\n",
        "- Our AGENTIC-DATA-SCRAPER platform uses 4 ontology levels:\n",
        "  - **Gist**: Foundational business concepts (organizations, people)\n",
        "  - **DBC Bridge**: Data Business Canvas (strategy alignment)\n",
        "  - **SOW**: Statement of Work contracts \n",
        "  - **Complete SOW**: Detailed contract specifications\n",
        "- The pie chart shows how much data we have at each level\n",
        "\n",
        "**Why visualization matters:**\n",
        "Visual analysis helps us quickly identify:\n",
        "- **Data gaps**: Which areas need more examples\n",
        "- **Data concentration**: Where we have the most detailed information\n",
        "- **Balance**: Whether our 4-level architecture is well-populated\n",
        "\n",
        "**What to expect:** \n",
        "- A horizontal bar chart showing entity counts\n",
        "- A pie chart showing the percentage split across ontology levels\n",
        "- This gives you a visual \"health check\" of our semantic data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Knowledge Graph Connection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class SemanticKnowledgeGraph:\n",
        "    \"\"\"Interface to the semantic knowledge graph with interactive capabilities\"\"\"\n",
        "    \n",
        "    def __init__(self, endpoint_url: str = \"http://localhost:3030/ds/sparql\"):\n",
        "        self.endpoint_url = endpoint_url\n",
        "        self.sparql = SPARQLWrapper(endpoint_url)\n",
        "        self.sparql.setReturnFormat(JSON)\n",
        "        \n",
        "        # Define namespace prefixes\n",
        "        self.prefixes = {\n",
        "            'gist': 'https://w3id.org/semanticarts/ontology/gistCore#',\n",
        "            'bridge': 'https://agentic-data-scraper.com/ontology/gist-dbc-bridge#',\n",
        "            'sow': 'https://agentic-data-scraper.com/ontology/sow#',\n",
        "            'csow': 'https://agentic-data-scraper.com/ontology/complete-sow#',\n",
        "            'rdfs': 'http://www.w3.org/2000/01/rdf-schema#',\n",
        "            'rdf': 'http://www.w3.org/1999/02/22-rdf-syntax-ns#',\n",
        "            'owl': 'http://www.w3.org/2002/07/owl#'\n",
        "        }\n",
        "        \n",
        "        self.prefix_string = '\\n'.join([f'PREFIX {k}: <{v}>' for k, v in self.prefixes.items()])\n",
        "        \n",
        "    def query(self, sparql_query: str) -> object:\n",
        "        \"\"\"Execute SPARQL query and return results as DataFrame\"\"\"\n",
        "        full_query = f\"{self.prefix_string}\\n\\n{sparql_query}\"\n",
        "        \n",
        "        try:\n",
        "            self.sparql.setQuery(full_query)\n",
        "            results = self.sparql.query().convert()\n",
        "            \n",
        "            if 'results' in results and 'bindings' in results['results']:\n",
        "                bindings = results['results']['bindings']\n",
        "                if not bindings:\n",
        "                    return pd.DataFrame()\n",
        "                \n",
        "                # Convert to DataFrame\n",
        "                data = []\n",
        "                for binding in bindings:\n",
        "                    row = {}\n",
        "                    for var, value in binding.items():\n",
        "                        if value['type'] == 'uri':\n",
        "                            # Simplify URIs by taking the fragment/last part\n",
        "                            row[var] = value['value'].split('#')[-1].split('/')[-1]\n",
        "                            row[f'{var}_full'] = value['value']  # Keep full URI\n",
        "                        else:\n",
        "                            row[var] = value['value']\n",
        "                    data.append(row)\n",
        "                \n",
        "                return pd.DataFrame(data)\n",
        "            \n",
        "            elif 'boolean' in results:\n",
        "                return pd.DataFrame({'result': [results['boolean']]})\n",
        "            \n",
        "            else:\n",
        "                return pd.DataFrame()\n",
        "                \n",
        "        except Exception as e:\n",
        "            print(f\"‚ùå Query error: {e}\")\n",
        "            return pd.DataFrame()\n",
        "    \n",
        "    def test_connection(self) -> bool:\n",
        "        \"\"\"Test connection to the knowledge graph\"\"\"\n",
        "        test_query = \"SELECT (COUNT(*) as ?count) WHERE { ?s ?p ?o }\"\n",
        "        result = self.query(test_query)\n",
        "        \n",
        "        if not result.empty and 'count' in result.columns:\n",
        "            count = int(result['count'].iloc[0])\n",
        "            print(f\"‚úÖ Connected to knowledge graph with {count:,} triples\")\n",
        "            return True\n",
        "        else:\n",
        "            print(\"‚ùå Failed to connect to knowledge graph\")\n",
        "            return False\n",
        "    \n",
        "    def get_statistics(self) -> Dict[str, Any]:\n",
        "        \"\"\"Get basic statistics about the knowledge graph\"\"\"\n",
        "        stats = {}\n",
        "        \n",
        "        # Total triples\n",
        "        total_query = \"SELECT (COUNT(*) as ?count) WHERE { ?s ?p ?o }\"\n",
        "        result = self.query(total_query)\n",
        "        stats['total_triples'] = int(result['count'].iloc[0]) if not result.empty else 0\n",
        "        \n",
        "        # Classes with instance counts\n",
        "        classes_query = \"\"\"\n",
        "        SELECT ?class (COUNT(?instance) as ?count) WHERE {\n",
        "            ?instance a ?class .\n",
        "            FILTER(\n",
        "                STRSTARTS(STR(?class), \"https://w3id.org/semanticarts/ontology/gistCore#\") ||\n",
        "                STRSTARTS(STR(?class), \"https://agentic-data-scraper.com/ontology/\")\n",
        "            )\n",
        "        }\n",
        "        GROUP BY ?class\n",
        "        ORDER BY DESC(?count)\n",
        "        \"\"\"\n",
        "        classes_df = self.query(classes_query)\n",
        "        stats['classes'] = classes_df.to_dict('records') if not classes_df.empty else []\n",
        "        \n",
        "        # Properties\n",
        "        properties_query = \"\"\"\n",
        "        SELECT DISTINCT ?property (COUNT(*) as ?usage) WHERE {\n",
        "            ?s ?property ?o .\n",
        "            FILTER(\n",
        "                STRSTARTS(STR(?property), \"https://agentic-data-scraper.com/ontology/\")\n",
        "            )\n",
        "        }\n",
        "        GROUP BY ?property\n",
        "        ORDER BY DESC(?usage)\n",
        "        \"\"\"\n",
        "        props_df = self.query(properties_query)\n",
        "        stats['properties'] = props_df.to_dict('records') if not props_df.empty else []\n",
        "        \n",
        "        return stats\n",
        "\n",
        "# Initialize connection\n",
        "kg = SemanticKnowledgeGraph()\n",
        "if kg.test_connection():\n",
        "    print(\"üöÄ Ready for semantic experiments!\")\n",
        "else:\n",
        "    print(\"‚ö†Ô∏è  Make sure Fuseki is running: docker-compose -f docker-compose.semantic.yml up -d\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Knowledge Graph Statistics and Overview\n",
        "\n",
        "This section provides a comprehensive statistical analysis of our knowledge graph structure. We extract and display key metrics that help us understand the scale, diversity, and organization of our semantic data.\n",
        "\n",
        "The analysis includes:\n",
        "- **Total Triples**: The fundamental RDF statements (subject-predicate-object) that make up our knowledge graph\n",
        "- **Class Distribution**: Which types of entities are most common in our data\n",
        "- **Property Usage**: Which relationships and attributes are used most frequently\n",
        "- **Inheritance Patterns**: How our ontology classes relate to each other through hierarchical relationships\n",
        "\n",
        "These statistics are crucial for understanding the quality and completeness of our knowledge graph, identifying potential gaps, and optimizing query performance."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Get comprehensive statistics\n",
        "stats = kg.get_statistics()\n",
        "\n",
        "print(f\"üìä Knowledge Graph Overview\")\n",
        "print(\"=\" * 40)\n",
        "print(f\"Total Triples: {stats['total_triples']:,}\")\n",
        "print(f\"Classes: {len(stats['classes'])}\")\n",
        "print(f\"Properties: {len(stats['properties'])}\")\n",
        "\n",
        "if stats['classes']:\n",
        "    print(\"\\nüèóÔ∏è  Top Classes by Instance Count:\")\n",
        "    for i, cls in enumerate(stats['classes'][:10]):\n",
        "        print(f\"  {i+1:2d}. {cls['class']:30} {cls['count']:>5} instances\")\n",
        "\n",
        "if stats['properties']:\n",
        "    print(\"\\nüîó Top Properties by Usage:\")\n",
        "    for i, prop in enumerate(stats['properties'][:10]):\n",
        "        print(f\"  {i+1:2d}. {prop['property']:30} {prop['usage']:>5} uses\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Statistical Visualization\n",
        "\n",
        "Now that we have the raw statistics, let's create visualizations to better understand the distribution and composition of our knowledge graph. The following charts help us quickly identify:\n",
        "\n",
        "- Which entity types (classes) dominate our data\n",
        "- How our ontology concepts are distributed across different vocabularies\n",
        "- The relative importance of different relationship types\n",
        "\n",
        "Visual analysis makes it easier to spot patterns and potential issues in our knowledge graph structure that might not be obvious from raw numbers alone."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualize class distribution\n",
        "if stats['classes']:\n",
        "    classes_df = pd.DataFrame(stats['classes'])\n",
        "    \n",
        "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))\n",
        "    \n",
        "    # Bar chart of top classes\n",
        "    top_classes = classes_df.head(10)\n",
        "    ax1.barh(top_classes['class'], top_classes['count'].astype(int))\n",
        "    ax1.set_title('Top 10 Classes by Instance Count')\n",
        "    ax1.set_xlabel('Number of Instances')\n",
        "    \n",
        "    # Pie chart of ontology distribution\n",
        "    classes_df['ontology'] = classes_df['class_full'].apply(lambda x: \n",
        "        'Gist' if 'gistCore' in x \n",
        "        else 'DBC Bridge' if 'gist-dbc-bridge' in x\n",
        "        else 'SOW' if 'sow' in x\n",
        "        else 'Complete SOW' if 'complete-sow' in x\n",
        "        else 'Other'\n",
        "    )\n",
        "    \n",
        "    ontology_counts = classes_df.groupby('ontology')['count'].sum().astype(int)\n",
        "    ax2.pie(ontology_counts.values, labels=ontology_counts.index, autopct='%1.1f%%')\n",
        "    ax2.set_title('Instance Distribution by Ontology Level')\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "else:\n",
        "    print(\"No class data available for visualization\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### üîç Interactive SPARQL Query Interface\n",
        "\n",
        "**What this does:** This cell creates an interactive interface for exploring our semantic knowledge graph using SPARQL queries, without needing to write code manually.\n",
        "\n",
        "**Understanding SPARQL queries:**\n",
        "- **SPARQL** is the standard query language for semantic data (like SQL is for databases)\n",
        "- It finds patterns in graph data by matching subjects, predicates, and objects\n",
        "- Example: \"Find all organizations that have a business model\"\n",
        "\n",
        "**The interactive interface provides:**\n",
        "\n",
        "**1. Predefined Queries:**\n",
        "- **All Classes**: Shows what types of entities exist in our knowledge graph\n",
        "- **Gist Organizations**: Lists all business organizations\n",
        "- **Data Assets**: Shows available data sources and their semantic mappings\n",
        "- **SOW Contracts**: Displays contract information and business challenges\n",
        "- **Property Usage**: Shows which relationships are most commonly used\n",
        "\n",
        "**2. Custom Query Area:**\n",
        "- You can modify existing queries or write your own\n",
        "- Results appear as interactive tables you can sort and explore\n",
        "\n",
        "**Why this is valuable:**\n",
        "In the AGENTIC-DATA-SCRAPER platform, business analysts and developers need to explore semantic data without being SPARQL experts. This interface allows:\n",
        "- Quick data exploration\n",
        "- Understanding available business concepts\n",
        "- Validating semantic mappings\n",
        "- Identifying patterns for code generation\n",
        "\n",
        "**What to expect:** \n",
        "- A dropdown menu with example queries\n",
        "- A text area where you can edit SPARQL\n",
        "- An execute button that runs queries and shows results\n",
        "- Interactive tables displaying the query results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4-Level Connectivity Analysis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Ontology Inheritance Analysis\n",
        "\n",
        "This section explores how our domain-specific classes relate to foundational semantic web vocabularies, particularly the Gist Core ontology. Understanding these inheritance relationships is crucial because:\n",
        "\n",
        "- **Semantic Interoperability**: By extending standard vocabularies, our data can integrate with other systems that use the same foundational concepts\n",
        "- **Reasoning Capabilities**: Inheritance allows semantic reasoners to infer additional facts based on class hierarchies\n",
        "- **Data Validation**: Class hierarchies provide structure for validating that our data conforms to expected patterns\n",
        "- **Query Optimization**: Understanding the class hierarchy helps write more efficient SPARQL queries\n",
        "\n",
        "The analysis shows which of our custom business concepts (like DataContract, ExecutiveTarget) are built upon standard Gist classes, creating a bridge between domain-specific business knowledge and universal semantic concepts."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Analyze inheritance relationships\n",
        "# Plain English: \"Show me all the custom classes we created and which standard Gist classes they extend from.\n",
        "# This shows how our domain-specific ontologies build upon the foundational Gist vocabulary\"\n",
        "inheritance_query = \"\"\"\n",
        "SELECT ?subclass ?superclass WHERE {\n",
        "    ?subclass rdfs:subClassOf ?superclass .\n",
        "    FILTER(\n",
        "        STRSTARTS(STR(?subclass), \"https://agentic-data-scraper.com/ontology/\") &&\n",
        "        STRSTARTS(STR(?superclass), \"https://w3id.org/semanticarts/ontology/gistCore#\")\n",
        "    )\n",
        "}\n",
        "ORDER BY ?subclass\n",
        "\"\"\"\n",
        "\n",
        "inheritance_results = kg.query(inheritance_query)\n",
        "\n",
        "print(\"üîó Inheritance Chain Analysis\")\n",
        "print(\"=\" * 40)\n",
        "\n",
        "if not inheritance_results.empty:\n",
        "    print(f\"‚úÖ Found {len(inheritance_results)} inheritance relationships:\")\n",
        "    print()\n",
        "    for _, row in inheritance_results.iterrows():\n",
        "        print(f\"  {row['subclass']:35} ‚Üí gist:{row['superclass']}\")\n",
        "    \n",
        "    print(\"\\nüìä Inheritance Summary:\")\n",
        "    gist_parents = inheritance_results.groupby('superclass').size().sort_values(ascending=False)\n",
        "    for parent, count in gist_parents.items():\n",
        "        print(f\"  gist:{parent}: {count} subclasses\")\n",
        "else:\n",
        "    print(\"‚ùå No inheritance relationships found\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Business Value Chain Analysis\n",
        "\n",
        "This analysis demonstrates one of the most powerful aspects of semantic knowledge graphs: connecting technical data processing activities to business outcomes and executive accountability. \n",
        "\n",
        "We trace the complete value creation pipeline:\n",
        "1. **Data Processing Tasks** - Technical activities that transform raw data\n",
        "2. **Value Propositions** - Business benefits created by these tasks\n",
        "3. **Executive Targets** - Strategic goals that the value supports\n",
        "4. **Ownership** - Which executives are accountable for achieving these targets\n",
        "\n",
        "This end-to-end traceability enables:\n",
        "- **Impact Assessment**: Understanding which technical changes affect business objectives\n",
        "- **Resource Prioritization**: Focusing development efforts on high-value activities\n",
        "- **Accountability Mapping**: Clear lines of responsibility from code to C-suite\n",
        "- **ROI Measurement**: Quantifying the business impact of data initiatives\n",
        "\n",
        "By representing these relationships semantically, we can automatically generate reports, detect orphaned processes, and ensure all technical work aligns with business strategy."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Analyze business value creation chains\n",
        "# Plain English: \"Find data processing tasks that create business value, and show me what specific\n",
        "# value they create, which executive targets they support, and who owns those targets\"\n",
        "value_chain_query = \"\"\"\n",
        "SELECT ?task ?value ?target ?owner WHERE {\n",
        "    ?task a bridge:DataProcessingTask .\n",
        "    ?task bridge:createsBusinessValue ?value .\n",
        "    ?value a bridge:ValueProposition .\n",
        "    \n",
        "    OPTIONAL {\n",
        "        ?canvas bridge:alignsWithTarget ?target .\n",
        "        ?target a bridge:ExecutiveTarget .\n",
        "        ?target bridge:ownedBy ?owner .\n",
        "        ?owner a gist:Person .\n",
        "    }\n",
        "}\n",
        "\"\"\"\n",
        "\n",
        "value_results = kg.query(value_chain_query)\n",
        "\n",
        "print(\"üí∞ Business Value Chain Analysis\")\n",
        "print(\"=\" * 40)\n",
        "\n",
        "if not value_results.empty:\n",
        "    print(f\"‚úÖ Found {len(value_results)} value creation relationship(s):\")\n",
        "    print()\n",
        "    for i, row in value_results.iterrows():\n",
        "        print(f\"Value Chain {i+1}:\")\n",
        "        print(f\"  Task:              {row['task']}\")\n",
        "        print(f\"  Creates Value:     {row['value']}\")\n",
        "        if pd.notna(row.get('target')):\n",
        "            print(f\"  Executive Target:  {row['target']}\")\n",
        "        if pd.notna(row.get('owner')):\n",
        "            print(f\"  Target Owner:      {row['owner']}\")\n",
        "        print()\n",
        "    \n",
        "    display(value_results)\n",
        "else:\n",
        "    print(\"‚ùå No value creation chains found\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Interactive SPARQL Query Interface\n",
        "\n",
        "This section provides an interactive environment for exploring our knowledge graph using SPARQL queries. SPARQL (SPARQL Protocol and RDF Query Language) is the standard query language for semantic web technologies, similar to how SQL queries relational databases.\n",
        "\n",
        "Key features of this interface:\n",
        "- **Predefined Queries**: Common analytical queries with plain English explanations\n",
        "- **Custom Query Execution**: Write and test your own SPARQL queries\n",
        "- **Result Formatting**: Automatically display results in readable tables\n",
        "- **Query Validation**: Real-time feedback on query syntax and execution\n",
        "\n",
        "The interface bridges the gap between technical SPARQL syntax and business questions, allowing users to:\n",
        "- Explore entity relationships without learning complex query syntax\n",
        "- Understand what each query accomplishes through natural language descriptions\n",
        "- Experiment with custom queries to answer specific business questions\n",
        "- Export results for further analysis\n",
        "\n",
        "This democratizes access to the knowledge graph, enabling both technical and business users to extract insights from our semantic data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Interactive query widget\n",
        "def create_interactive_query_interface():\n",
        "    # Predefined queries with plain English explanations\n",
        "    predefined_queries = {\n",
        "        # Plain English: \"Show me all types of entities and count how many instances we have of each\"\n",
        "        \"All Classes\": \"\"\"\n",
        "SELECT DISTINCT ?class (COUNT(?instance) as ?count) WHERE {\n",
        "    ?instance a ?class .\n",
        "}\n",
        "GROUP BY ?class\n",
        "ORDER BY DESC(?count)\n",
        "LIMIT 20\"\"\",\n",
        "        \n",
        "        # Plain English: \"List all organizations in our knowledge graph and their labels\"\n",
        "        \"Gist Organizations\": \"\"\"\n",
        "SELECT ?org ?label WHERE {\n",
        "    ?org a gist:Organization .\n",
        "    OPTIONAL { ?org rdfs:label ?label }\n",
        "}\"\"\",\n",
        "        \n",
        "        # Plain English: \"Find all data assets, their readable names, and what semantic concepts they map to\"\n",
        "        \"Data Assets\": \"\"\"\n",
        "SELECT ?asset ?label ?mapping WHERE {\n",
        "    ?asset a bridge:DataAsset .\n",
        "    OPTIONAL { ?asset rdfs:label ?label }\n",
        "    OPTIONAL { ?asset bridge:hasSemanticMapping ?mapping }\n",
        "}\"\"\",\n",
        "        \n",
        "        # Plain English: \"Show Statement of Work contracts with their business challenges and desired outcomes\"\n",
        "        \"SOW Contracts\": \"\"\"\n",
        "SELECT ?sow ?challenge ?outcome WHERE {\n",
        "    ?sow a csow:SemanticStatementOfWork .\n",
        "    OPTIONAL { ?sow csow:hasBusinessChallenge ?challenge }\n",
        "    OPTIONAL { ?sow csow:hasDesiredOutcome ?outcome }\n",
        "}\"\"\",\n",
        "        \n",
        "        # Plain English: \"Count how many times each relationship type is used in our domain ontologies\"\n",
        "        \"Property Usage\": \"\"\"\n",
        "SELECT ?property (COUNT(*) as ?usage) WHERE {\n",
        "    ?s ?property ?o .\n",
        "    FILTER(STRSTARTS(STR(?property), \"https://agentic-data-scraper.com/ontology/\"))\n",
        "}\n",
        "GROUP BY ?property\n",
        "ORDER BY DESC(?usage)\"\"\"\n",
        "    }\n",
        "    \n",
        "    # Widget setup\n",
        "    query_dropdown = widgets.Dropdown(\n",
        "        options=list(predefined_queries.keys()),\n",
        "        value=list(predefined_queries.keys())[0],\n",
        "        description='Query:',\n",
        "        style={'description_width': 'initial'}\n",
        "    )\n",
        "    \n",
        "    query_text = widgets.Textarea(\n",
        "        value=predefined_queries[query_dropdown.value],\n",
        "        placeholder='Enter your SPARQL query here...',\n",
        "        description='SPARQL:',\n",
        "        style={'description_width': 'initial'},\n",
        "        layout=widgets.Layout(width='100%', height='200px')\n",
        "    )\n",
        "    \n",
        "    execute_button = widgets.Button(\n",
        "        description='Execute Query',\n",
        "        button_style='primary',\n",
        "        icon='play'\n",
        "    )\n",
        "    \n",
        "    output_area = widgets.Output()\n",
        "    \n",
        "    def update_query(change):\n",
        "        query_text.value = predefined_queries[change['new']]\n",
        "    \n",
        "    def execute_query(button):\n",
        "        with output_area:\n",
        "            output_area.clear_output()\n",
        "            print(f\"üîç Executing query: {query_dropdown.value}\")\n",
        "            print(\"=\" * 50)\n",
        "            \n",
        "            try:\n",
        "                result = kg.query(query_text.value)\n",
        "                \n",
        "                if result.empty:\n",
        "                    print(\"No results found\")\n",
        "                else:\n",
        "                    print(f\"‚úÖ Found {len(result)} result(s)\")\n",
        "                    display(result)\n",
        "                    \n",
        "                    # Show basic statistics if numeric columns exist\n",
        "                    numeric_cols = result.select_dtypes(include=['int64', 'float64']).columns\n",
        "                    if len(numeric_cols) > 0:\n",
        "                        print(\"\\nüìä Numeric Summary:\")\n",
        "                        display(result[numeric_cols].describe())\n",
        "                        \n",
        "            except Exception as e:\n",
        "                print(f\"‚ùå Query error: {e}\")\n",
        "    \n",
        "    query_dropdown.observe(update_query, names='value')\n",
        "    execute_button.on_click(execute_query)\n",
        "    \n",
        "    # Layout\n",
        "    interface = widgets.VBox([\n",
        "        widgets.HTML(\"<h3>üîç Interactive SPARQL Query Interface</h3>\"),\n",
        "        query_dropdown,\n",
        "        query_text,\n",
        "        execute_button,\n",
        "        output_area\n",
        "    ])\n",
        "    \n",
        "    return interface\n",
        "\n",
        "# Create and display the interface\n",
        "query_interface = create_interactive_query_interface()\n",
        "display(query_interface)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Knowledge Graph Visualization\n",
        "\n",
        "Visualization transforms abstract RDF triples into intuitive network diagrams that reveal the structure and relationships within our knowledge graph. This interactive visualization helps users:\n",
        "\n",
        "**Understand Graph Structure**:\n",
        "- See how entities connect through relationships\n",
        "- Identify central nodes and connection patterns\n",
        "- Discover unexpected relationships between business concepts\n",
        "\n",
        "**Visual Analysis Capabilities**:\n",
        "- **Node Sizing**: Larger nodes represent entities with more connections\n",
        "- **Color Coding**: Different colors distinguish entity types (organizations, processes, targets)\n",
        "- **Interactive Exploration**: Click and drag to explore specific areas of interest\n",
        "- **Layout Algorithms**: Automatic positioning that groups related concepts together\n",
        "\n",
        "**Business Value**:\n",
        "- **Pattern Recognition**: Spot business process bottlenecks or opportunities\n",
        "- **Impact Analysis**: Visualize how changes might ripple through connected systems\n",
        "- **Communication Tool**: Present complex data relationships to stakeholders\n",
        "- **Data Quality**: Identify orphaned entities or missing connections\n",
        "\n",
        "The visualization focuses on custom business relationships while filtering out technical RDF metadata, providing a clear view of domain-specific knowledge patterns."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def create_knowledge_graph_visualization():\n",
        "    \"\"\"Create an interactive network visualization of the knowledge graph\"\"\"\n",
        "    \n",
        "    # Query for relationships\n",
        "    # Plain English: \"Find pairs of entities connected by our custom relationships,\n",
        "    # limiting to 50 connections to keep the visualization manageable\"\n",
        "    relationships_query = \"\"\"\n",
        "    SELECT ?subject ?predicate ?object WHERE {\n",
        "        ?subject ?predicate ?object .\n",
        "        FILTER(\n",
        "            STRSTARTS(STR(?predicate), \"https://agentic-data-scraper.com/ontology/\") &&\n",
        "            isURI(?object)\n",
        "        )\n",
        "    }\n",
        "    LIMIT 50\n",
        "    \"\"\"\n",
        "    \n",
        "    relationships = kg.query(relationships_query)\n",
        "    \n",
        "    if relationships.empty:\n",
        "        print(\"‚ùå No relationships found for visualization\")\n",
        "        return\n",
        "    \n",
        "    # Create NetworkX graph\n",
        "    G = nx.DiGraph()\n",
        "    \n",
        "    # Add nodes and edges\n",
        "    for _, row in relationships.iterrows():\n",
        "        subject = row['subject']\n",
        "        predicate = row['predicate']\n",
        "        obj = row['object']\n",
        "        \n",
        "        G.add_edge(subject, obj, label=predicate)\n",
        "    \n",
        "    # Create layout\n",
        "    pos = nx.spring_layout(G, k=3, iterations=50)\n",
        "    \n",
        "    # Prepare data for Plotly\n",
        "    edge_x = []\n",
        "    edge_y = []\n",
        "    edge_info = []\n",
        "    \n",
        "    for edge in G.edges(data=True):\n",
        "        x0, y0 = pos[edge[0]]\n",
        "        x1, y1 = pos[edge[1]]\n",
        "        edge_x.extend([x0, x1, None])\n",
        "        edge_y.extend([y0, y1, None])\n",
        "        edge_info.append(edge[2]['label'])\n",
        "    \n",
        "    edge_trace = go.Scatter(\n",
        "        x=edge_x, y=edge_y,\n",
        "        line=dict(width=0.5, color='#888'),\n",
        "        hoverinfo='none',\n",
        "        mode='lines'\n",
        "    )\n",
        "    \n",
        "    node_x = []\n",
        "    node_y = []\n",
        "    node_text = []\n",
        "    node_colors = []\n",
        "    \n",
        "    for node in G.nodes():\n",
        "        x, y = pos[node]\n",
        "        node_x.append(x)\n",
        "        node_y.append(y)\n",
        "        node_text.append(node)\n",
        "        \n",
        "        # Color nodes by ontology level\n",
        "        if 'gistCore' in node:\n",
        "            node_colors.append('red')  # Level 1: Gist\n",
        "        elif 'gist-dbc-bridge' in node:\n",
        "            node_colors.append('blue')  # Level 2: DBC\n",
        "        elif 'sow' in node:\n",
        "            node_colors.append('green')  # Level 3: SOW\n",
        "        else:\n",
        "            node_colors.append('orange')  # Other\n",
        "    \n",
        "    node_trace = go.Scatter(\n",
        "        x=node_x, y=node_y,\n",
        "        mode='markers+text',\n",
        "        hoverinfo='text',\n",
        "        text=node_text,\n",
        "        textposition=\"middle center\",\n",
        "        marker=dict(\n",
        "            showscale=False,\n",
        "            color=node_colors,\n",
        "            size=10,\n",
        "            line=dict(width=2)\n",
        "        )\n",
        "    )\n",
        "    \n",
        "    # Create figure with updated Plotly API\n",
        "    fig = go.Figure(\n",
        "        data=[edge_trace, node_trace],\n",
        "        layout=go.Layout(\n",
        "            title=dict(\n",
        "                text='üåê Knowledge Graph Visualization',\n",
        "                font=dict(size=16)\n",
        "            ),\n",
        "            showlegend=False,\n",
        "            hovermode='closest',\n",
        "            margin=dict(b=20,l=5,r=5,t=40),\n",
        "            annotations=[\n",
        "                dict(\n",
        "                    text=\"Colors: Red=Gist, Blue=DBC Bridge, Green=SOW, Orange=Other\",\n",
        "                    showarrow=False,\n",
        "                    xref=\"paper\", yref=\"paper\",\n",
        "                    x=0.005, y=-0.002,\n",
        "                    xanchor=\"left\", yanchor=\"bottom\",\n",
        "                    font=dict(size=12)\n",
        "                )\n",
        "            ],\n",
        "            xaxis=dict(showgrid=False, zeroline=False, showticklabels=False),\n",
        "            yaxis=dict(showgrid=False, zeroline=False, showticklabels=False)\n",
        "        )\n",
        "    )\n",
        "    \n",
        "    fig.show()\n",
        "    \n",
        "    print(f\"üìä Visualization Statistics:\")\n",
        "    print(f\"  Nodes: {len(G.nodes())}\")\n",
        "    print(f\"  Edges: {len(G.edges())}\")\n",
        "    print(f\"  Density: {nx.density(G):.3f}\")\n",
        "\n",
        "# Create visualization\n",
        "create_knowledge_graph_visualization()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Semantic Reasoning Experiments\n",
        "\n",
        "Semantic reasoning is where knowledge graphs truly excel beyond traditional databases. Reasoning engines can automatically infer new facts from existing data using logical rules and ontological relationships.\n",
        "\n",
        "**Types of Reasoning Demonstrated**:\n",
        "\n",
        "**Transitive Relationships**: \n",
        "- Follow multi-step connections (org ‚Üí canvas ‚Üí SOW ‚Üí contract ‚Üí task)\n",
        "- Automatically discover indirect relationships without explicit links\n",
        "- Enables impact analysis across the entire business-to-technical stack\n",
        "\n",
        "**Class Hierarchy Reasoning**:\n",
        "- Automatically infer that instances of specific classes are also instances of their parent classes\n",
        "- Query for general types and get specific instances automatically\n",
        "- Enables flexible querying without knowing exact entity types\n",
        "\n",
        "**Property Reasoning**:\n",
        "- Use inverse properties to query relationships from either direction\n",
        "- Apply property chains to discover multi-step relationships\n",
        "- Leverage property characteristics (symmetric, transitive, functional)\n",
        "\n",
        "**Business Applications**:\n",
        "- **Compliance**: Automatically verify that all business models have implementing SOWs\n",
        "- **Gap Analysis**: Identify missing links in value creation chains\n",
        "- **Change Impact**: Predict what business processes are affected by technical changes\n",
        "- **Data Lineage**: Trace data flow from source to business outcome\n",
        "\n",
        "This demonstrates how semantic technologies enable intelligent automation and discovery that would require complex programming in traditional systems."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Test semantic reasoning capabilities\n",
        "def test_semantic_reasoning():\n",
        "    \"\"\"Test various semantic reasoning queries\"\"\"\n",
        "    \n",
        "    reasoning_tests = {\n",
        "        # Plain English: \"Follow the chain from organizations all the way to data processing tasks,\n",
        "        # showing how business entities connect to technical implementation\"\n",
        "        \"Transitive Relationships\": \"\"\"\n",
        "        SELECT ?org ?task WHERE {\n",
        "            ?org a gist:Organization .\n",
        "            ?org bridge:hasBusinessModel ?canvas .\n",
        "            ?canvas bridge:implementedBySOW ?sow .\n",
        "            ?sow bridge:realizesContract ?contract .\n",
        "            ?contract bridge:executedByTask ?task .\n",
        "            # This shows transitive relationship: org -> canvas -> sow -> contract -> task\n",
        "        }\"\"\",\n",
        "        \n",
        "        # Plain English: \"Show instances of our custom classes and what standard Gist classes they inherit from\"\n",
        "        \"Class Hierarchy\": \"\"\"\n",
        "        SELECT ?instance ?specificType ?generalType WHERE {\n",
        "            ?instance a ?specificType .\n",
        "            ?specificType rdfs:subClassOf ?generalType .\n",
        "            FILTER(STRSTARTS(STR(?generalType), \"https://w3id.org/semanticarts/ontology/gistCore#\"))\n",
        "        }\"\"\",\n",
        "        \n",
        "        # Plain English: \"Find tasks and what business value they create (reverse relationship lookup)\"\n",
        "        \"Inverse Relationships\": \"\"\"\n",
        "        SELECT ?value ?task WHERE {\n",
        "            ?task bridge:createsBusinessValue ?value .\n",
        "            # Find what creates specific business values\n",
        "        }\"\"\",\n",
        "        \n",
        "        # Plain English: \"Count how many intermediate steps exist between organizations and data processing tasks\"\n",
        "        \"Multi-hop Connections\": \"\"\"\n",
        "        SELECT ?start ?end (COUNT(?intermediate) as ?hops) WHERE {\n",
        "            ?start a gist:Organization .\n",
        "            ?start ?p1 ?intermediate .\n",
        "            ?intermediate ?p2 ?end .\n",
        "            ?end a bridge:DataProcessingTask .\n",
        "        }\n",
        "        GROUP BY ?start ?end\n",
        "        \"\"\"\n",
        "    }\n",
        "    \n",
        "    print(\"üß† Semantic Reasoning Tests\")\n",
        "    print(\"=\" * 50)\n",
        "    \n",
        "    for test_name, query in reasoning_tests.items():\n",
        "        print(f\"\\nüîç {test_name}:\")\n",
        "        result = kg.query(query)\n",
        "        \n",
        "        if not result.empty:\n",
        "            print(f\"  ‚úÖ Found {len(result)} result(s)\")\n",
        "            if len(result) <= 5:  # Show results if few enough\n",
        "                display(result)\n",
        "            else:\n",
        "                print(f\"  üìä Sample results:\")\n",
        "                display(result.head())\n",
        "        else:\n",
        "            print(f\"  ‚ùå No results found\")\n",
        "\n",
        "test_semantic_reasoning()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Custom Query Experiments"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### üé® Professional KuzuDB + yFiles Visualization Class\n",
        "\n",
        "**What this does:** This cell defines our advanced visualization system that combines KuzuDB (high-performance graph database) with yFiles (professional graph visualization) to create enterprise-grade semantic knowledge graph exploration.\n",
        "\n",
        "**Understanding the technology stack:**\n",
        "\n",
        "**1. KuzuDB - High-Performance Graph Database:**\n",
        "- **In-memory processing**: Extremely fast query execution\n",
        "- **Optimized for analytics**: Perfect for complex graph pattern analysis  \n",
        "- **Cypher-compatible**: Uses familiar graph query language\n",
        "- **Why we use it**: Traditional databases struggle with highly connected semantic data\n",
        "\n",
        "**2. yFiles - Professional Graph Visualization:**\n",
        "- **Enterprise-grade**: Used by major corporations for network visualization\n",
        "- **Interactive exploration**: Zoom, pan, filter, and drill-down capabilities\n",
        "- **Professional layouts**: Automatic arrangement of complex graphs\n",
        "- **Export capabilities**: Save visualizations for presentations and reports\n",
        "\n",
        "**Our 4-level color scheme:**\n",
        "- üî¥ **Red (Gist)**: Foundation layer - core business concepts\n",
        "- üîµ **Teal (Bridge)**: Strategy layer - Data Business Canvas\n",
        "- üîµ **Blue (SOW)**: Planning layer - Statement of Work contracts  \n",
        "- üü¢ **Green (Contracts)**: Execution layer - Data processing tasks\n",
        "\n",
        "**Key capabilities of our class:**\n",
        "1. **Data Loading**: Converts SPARQL results into KuzuDB format\n",
        "2. **Schema Creation**: Defines optimized database structure for semantic data\n",
        "3. **Professional Visualization**: Creates interactive graph exploration interface\n",
        "4. **Layer Analysis**: Shows connectivity patterns between ontology levels\n",
        "\n",
        "**Why this matters for AGENTIC-DATA-SCRAPER:**\n",
        "Professional visualization helps stakeholders understand:\n",
        "- How business requirements connect to technical implementation\n",
        "- Where semantic gaps exist that need filling\n",
        "- The complexity and relationships in their data pipeline requirements\n",
        "\n",
        "**What to expect:** A comprehensive class definition that will be used to create professional interactive semantic visualizations."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### üöÄ KuzuDB + yFiles Implementation & Execution\n",
        "\n",
        "**What this does:** This is the main execution cell that brings everything together - it initializes our KuzuDB database, loads our semantic data, and creates the professional yFiles visualization.\n",
        "\n",
        "**Step-by-step process:**\n",
        "\n",
        "**1. Database Initialization:**\n",
        "- Creates a high-performance in-memory KuzuDB instance\n",
        "- This database will temporarily hold our semantic data for fast querying\n",
        "\n",
        "**2. Schema Creation:**\n",
        "- Defines the structure for storing semantic entities and relationships\n",
        "- Creates optimized tables for our 4-level ontology architecture\n",
        "\n",
        "**3. Data Loading:**\n",
        "- Pulls all semantic data from our SPARQL endpoint\n",
        "- Transforms it into KuzuDB's optimized format\n",
        "- Preserves all relationships and metadata\n",
        "\n",
        "**4. yFiles Visualization:**\n",
        "- Creates a professional interactive graph widget\n",
        "- Uses the Cypher query: `MATCH (a)-[b]->(c) RETURN * LIMIT 100`\n",
        "- This finds up to 100 connected entity pairs to visualize\n",
        "\n",
        "**5. Analysis & Insights:**\n",
        "- Shows connectivity statistics\n",
        "- Displays layer distribution\n",
        "- Provides professional summary of our semantic architecture\n",
        "\n",
        "**What makes this powerful:**\n",
        "- **Performance**: KuzuDB processes graph queries 10-100x faster than traditional databases\n",
        "- **Interactivity**: yFiles provides professional-grade exploration capabilities\n",
        "- **Scalability**: Can handle large enterprise knowledge graphs\n",
        "- **Professional quality**: Suitable for presentations to executives and stakeholders\n",
        "\n",
        "**Expected outcome:**\n",
        "A complete professional visualization of our AGENTIC-DATA-SCRAPER semantic knowledge graph, demonstrating how business requirements flow through our 4-level architecture to generate technical implementations.\n",
        "\n",
        "**This demonstrates:** The power of linked data reusability across multiple ontology levels - showing how semantic technologies enable automated code generation from business requirements."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Performance Analysis\n",
        "\n",
        "Understanding query performance is crucial for building responsive semantic applications. This section benchmarks different types of SPARQL queries to identify performance patterns and optimization opportunities.\n",
        "\n",
        "**Query Types Benchmarked**:\n",
        "\n",
        "**Simple Operations**:\n",
        "- **Triple Counts**: Baseline performance for basic graph traversal\n",
        "- **Class Instance Retrieval**: How quickly we can find entities of specific types\n",
        "\n",
        "**Pattern Matching**:\n",
        "- **Property Patterns**: Performance of filtering by specific relationships\n",
        "- **Complex Joins**: Multi-step relationship traversal costs\n",
        "\n",
        "**Reasoning Operations**:\n",
        "- **Inheritance Queries**: Cost of class hierarchy navigation\n",
        "- **Transitive Relationships**: Performance impact of multi-hop connections\n",
        "\n",
        "**Performance Insights**:\n",
        "- Identifies query patterns that scale well with graph size\n",
        "- Reveals bottlenecks that may require index optimization\n",
        "- Guides query optimization strategies for production applications\n",
        "- Helps estimate resource requirements for larger knowledge graphs\n",
        "\n",
        "**Optimization Strategies**:\n",
        "- Index commonly queried properties\n",
        "- Limit result sets for exploratory queries\n",
        "- Use FILTER clauses to reduce intermediate results\n",
        "- Consider materialized views for expensive reasoning queries\n",
        "\n",
        "This analysis helps ensure our semantic applications remain responsive as the knowledge graph grows in size and complexity."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import time\n",
        "\n",
        "def benchmark_queries():\n",
        "    \"\"\"Benchmark different types of queries for performance analysis\"\"\"\n",
        "    \n",
        "    benchmark_queries = {\n",
        "        \"Simple Count\": \"SELECT (COUNT(*) as ?count) WHERE { ?s ?p ?o }\",\n",
        "        \"Class Instances\": \"SELECT * WHERE { ?s a ?type } LIMIT 100\",\n",
        "        \"Property Patterns\": \"SELECT * WHERE { ?s bridge:hasBusinessModel ?o } LIMIT 10\",\n",
        "        \"Complex Join\": \"\"\"\n",
        "        SELECT ?org ?canvas ?sow WHERE {\n",
        "            ?org a gist:Organization .\n",
        "            ?org bridge:hasBusinessModel ?canvas .\n",
        "            ?canvas bridge:implementedBySOW ?sow .\n",
        "        }\"\"\",\n",
        "        \"Inheritance Query\": \"\"\"\n",
        "        SELECT ?sub ?super WHERE {\n",
        "            ?sub rdfs:subClassOf ?super .\n",
        "        } LIMIT 20\"\"\"\n",
        "    }\n",
        "    \n",
        "    print(\"‚ö° Query Performance Benchmark\")\n",
        "    print(\"=\" * 40)\n",
        "    \n",
        "    performance_results = []\n",
        "    \n",
        "    for query_name, query in benchmark_queries.items():\n",
        "        # Run query multiple times for average\n",
        "        times = []\n",
        "        for _ in range(3):\n",
        "            start_time = time.time()\n",
        "            result = kg.query(query)\n",
        "            end_time = time.time()\n",
        "            times.append(end_time - start_time)\n",
        "        \n",
        "        avg_time = sum(times) / len(times)\n",
        "        result_count = len(result) if not result.empty else 0\n",
        "        \n",
        "        performance_results.append({\n",
        "            'Query': query_name,\n",
        "            'Avg Time (s)': f\"{avg_time:.4f}\",\n",
        "            'Results': result_count\n",
        "        })\n",
        "        \n",
        "        print(f\"  {query_name:20} {avg_time:.4f}s ({result_count} results)\")\n",
        "    \n",
        "    # Create performance DataFrame\n",
        "    perf_df = pd.DataFrame(performance_results)\n",
        "    \n",
        "    # Visualize performance\n",
        "    fig, ax = plt.subplots(figsize=(10, 6))\n",
        "    times_float = [float(t) for t in perf_df['Avg Time (s)']]\n",
        "    bars = ax.bar(perf_df['Query'], times_float)\n",
        "    ax.set_title('Query Performance Comparison')\n",
        "    ax.set_ylabel('Average Time (seconds)')\n",
        "    ax.set_xlabel('Query Type')\n",
        "    plt.xticks(rotation=45, ha='right')\n",
        "    \n",
        "    # Add value labels on bars\n",
        "    for bar, time_val in zip(bars, times_float):\n",
        "        height = bar.get_height()\n",
        "        ax.text(bar.get_x() + bar.get_width()/2., height + 0.001,\n",
        "                f'{time_val:.4f}s', ha='center', va='bottom')\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "    \n",
        "    return perf_df\n",
        "\n",
        "performance_data = benchmark_queries()\n",
        "display(performance_data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Export and Save Results\n",
        "\n",
        "This section demonstrates how to persist and share the insights generated from our semantic knowledge graph analysis. Exporting results is crucial for:\n",
        "\n",
        "**Data Integration**:\n",
        "- Export RDF data for import into other semantic systems\n",
        "- Generate standard formats (Turtle, JSON-LD, N-Triples) for interoperability\n",
        "- Create flat file exports for integration with traditional business intelligence tools\n",
        "\n",
        "**Visualization and Reporting**:\n",
        "- Save interactive visualizations for stakeholder presentations\n",
        "- Generate static reports summarizing key findings\n",
        "- Export network diagrams in formats suitable for documentation\n",
        "\n",
        "**Professional Visualization**:\n",
        "- Leverage advanced graph visualization libraries like yFiles\n",
        "- Create production-ready visual representations\n",
        "- Generate high-quality exports for publications and presentations\n",
        "\n",
        "**Backup and Versioning**:\n",
        "- Preserve snapshots of knowledge graph state\n",
        "- Enable reproducible analysis and audit trails\n",
        "- Support version control for ontology evolution\n",
        "\n",
        "**Integration Capabilities**:\n",
        "- Bridge semantic technologies with enterprise data architectures\n",
        "- Enable embedding of knowledge graph insights into existing workflows\n",
        "- Support both batch and real-time export scenarios\n",
        "\n",
        "The export functionality ensures that our semantic analysis can be integrated into broader organizational knowledge management and decision-making processes."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Next Steps and Experimentation Ideas\n",
        "\n",
        "This notebook provides a comprehensive foundation for experimenting with the semantic knowledge graph. Here are some ideas for further exploration:\n",
        "\n",
        "### üî¨ **Experiment Ideas**\n",
        "1. **Add New Ontology Classes**: Extend the ontologies with domain-specific classes\n",
        "2. **Create Complex Queries**: Build multi-hop reasoning queries\n",
        "3. **Visualization Enhancements**: Create specialized visualizations for different aspects\n",
        "4. **Performance Optimization**: Test query optimization strategies\n",
        "5. **Data Integration**: Load real business data and map it to the ontologies\n",
        "\n",
        "### üöÄ **Application Development**\n",
        "1. **Semantic Search**: Build search interfaces using the knowledge graph\n",
        "2. **Business Intelligence**: Create dashboards based on semantic queries\n",
        "3. **Automated Reasoning**: Implement inference rules for business logic\n",
        "4. **Data Quality**: Use semantic constraints for data validation\n",
        "5. **Integration APIs**: Build REST APIs over the semantic layer\n",
        "\n",
        "### üìä **Analytics and Insights**\n",
        "1. **Graph Analytics**: Use NetworkX for advanced graph analysis\n",
        "2. **Pattern Discovery**: Find interesting patterns in the semantic data\n",
        "3. **Anomaly Detection**: Identify semantic inconsistencies\n",
        "4. **Recommendation Systems**: Build recommendations using semantic similarity\n",
        "5. **Predictive Models**: Create ML models using semantic features\n",
        "\n",
        "---\n",
        "\n",
        "**Happy experimenting! üéâ**\n",
        "\n",
        "The semantic infrastructure is now ready for building sophisticated knowledge-driven applications."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### üè¢ Level 1: Organization - EuroEnergy Trading Solutions\n",
        "\n",
        "**What this creates:** A real organization instance in our semantic knowledge graph that demonstrates how business entities are represented."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### üìã Level 2: Data Business Canvas - Renewable Energy Trading Strategy\n",
        "\n",
        "**What this creates:** A complete business strategy instance showing how organizations plan their data-driven initiatives."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### üìÑ Level 3: Statement of Work - Power Generation Analytics Implementation\n",
        "\n",
        "**What this creates:** A detailed SOW contract instance that bridges business requirements to technical implementation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "### üè¢ Level 1: Organization - EuroEnergy Trading Solutions\n",
        "\n",
        "## What this creates:** A real organization instance in our semantic knowledge graph that demonstrates how business entities are represented.\n",
        "\n",
        "def create_euroenergy_organization():\n",
        "    \"\"\"Generate realistic organization data for European power trading company\"\"\"\n",
        "    \n",
        "    # Create SPARQL INSERT query to add real organization data\n",
        "    # Plain English: \"Create EuroEnergy Trading Solutions as a real organization instance\n",
        "    # with headquarters in Amsterdam, focusing on renewable energy trading\"\n",
        "    org_insert_query = \"\"\"\n",
        "    INSERT DATA {\n",
        "        <https://agentic-data-scraper.com/instances/org/euroenergy-trading> a gist:Organization ;\n",
        "            rdfs:label \"EuroEnergy Trading Solutions B.V.\" ;\n",
        "            gist:hasName \"EuroEnergy Trading Solutions\" ;\n",
        "            gist:isLocatedAt <https://agentic-data-scraper.com/instances/place/amsterdam> ;\n",
        "            bridge:hasBusinessFocus \"Renewable Energy Trading\" ;\n",
        "            bridge:operatesInMarket \"European Power Exchange\" ;\n",
        "            bridge:hasRegulation \"EU Renewable Energy Directive 2018/2001\" .\n",
        "            \n",
        "        <https://agentic-data-scraper.com/instances/place/amsterdam> a gist:Place ;\n",
        "            rdfs:label \"Amsterdam, Netherlands\" ;\n",
        "            gist:hasName \"Amsterdam\" .\n",
        "            \n",
        "        <https://agentic-data-scraper.com/instances/person/ceo-martinez> a gist:Person ;\n",
        "            rdfs:label \"Elena Martinez\" ;\n",
        "            gist:hasName \"Elena Martinez\" ;\n",
        "            bridge:hasRole \"Chief Executive Officer\" ;\n",
        "            bridge:worksFor <https://agentic-data-scraper.com/instances/org/euroenergy-trading> .\n",
        "    }\n",
        "    \"\"\"\n",
        "    \n",
        "    print(\"üè¢ Creating EuroEnergy Trading Solutions Organization\")\n",
        "    print(\"=\" * 55)\n",
        "    print(\"üìç Location: Amsterdam, Netherlands\")\n",
        "    print(\"üéØ Focus: Renewable Energy Trading in European Markets\")\n",
        "    print(\"üë§ CEO: Elena Martinez\")\n",
        "    print(\"üìã Regulation: EU Renewable Energy Directive 2018/2001\")\n",
        "    \n",
        "    # Visualization of organization structure\n",
        "    org_data = {\n",
        "        'Company': ['EuroEnergy Trading Solutions B.V.'],\n",
        "        'Location': ['Amsterdam, Netherlands'],\n",
        "        'CEO': ['Elena Martinez'],\n",
        "        'Market Focus': ['European Power Exchange'],\n",
        "        'Regulation': ['EU Directive 2018/2001']\n",
        "    }\n",
        "    \n",
        "    org_df = pd.DataFrame(org_data)\n",
        "    \n",
        "    # Create visual representation\n",
        "    fig, ax = plt.subplots(figsize=(12, 6))\n",
        "    \n",
        "    # Company info as organized layout\n",
        "    y_pos = [4, 3, 2, 1, 0]\n",
        "    labels = ['Company', 'Location', 'CEO', 'Market Focus', 'Regulation']\n",
        "    values = ['EuroEnergy Trading Solutions B.V.', 'Amsterdam, Netherlands', \n",
        "              'Elena Martinez', 'European Power Exchange', 'EU Directive 2018/2001']\n",
        "    \n",
        "    colors = ['#FF6B6B', '#4ECDC4', '#45B7D1', '#96CEB4', '#FFEAA7']\n",
        "    \n",
        "    for i, (label, value, color) in enumerate(zip(labels, values, colors)):\n",
        "        ax.barh(y_pos[i], 1, color=color, alpha=0.7)\n",
        "        ax.text(0.05, y_pos[i], f\"{label}: {value}\", \n",
        "                va='center', fontweight='bold', fontsize=10)\n",
        "    \n",
        "    ax.set_xlim(0, 1)\n",
        "    ax.set_ylim(-0.5, 4.5)\n",
        "    ax.set_yticks([])\n",
        "    ax.set_xticks([])\n",
        "    ax.set_title('üè¢ EuroEnergy Trading Solutions - Organization Profile', \n",
        "                 fontsize=14, fontweight='bold', pad=20)\n",
        "    \n",
        "    # Remove spines\n",
        "    for spine in ax.spines.values():\n",
        "        spine.set_visible(False)\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "    \n",
        "    print(\"\\n‚úÖ Organization instance created in semantic knowledge graph\")\n",
        "    print(\"üîó This demonstrates Level 1 (Gist Foundation) with real business entity\")\n",
        "\n",
        "# Execute organization creation\n",
        "create_euroenergy_organization()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Power Generation SOW Example\n",
        "\n",
        "This section demonstrates how semantic knowledge graphs bridge high-level business requirements to specific technical implementations. The Statement of Work (SOW) represents a formal contract that:\n",
        "\n",
        "- **Translates Business Needs**: Converts executive targets into actionable technical requirements\n",
        "- **Defines Scope**: Specifies exactly what data processing capabilities will be built\n",
        "- **Establishes Accountability**: Links technical deliverables to business stakeholders\n",
        "- **Enables Traceability**: Creates a semantic chain from business strategy to code implementation\n",
        "\n",
        "The SOW instance shows how semantic technologies can automatically generate contract documents that maintain formal linkages between business intent and technical execution, enabling automated compliance checking and impact analysis."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# üöÄ Next Steps & Further Exploration\n",
        "\n",
        "## Immediate Applications\n",
        "Now that you understand semantic knowledge graphs, consider these next steps:\n",
        "\n",
        "### üè¢ For Your Organization\n",
        "1. **Inventory Current Data**: Map existing data sources and their relationships\n",
        "2. **Identify Use Cases**: Find high-value scenarios where semantic graphs provide advantages\n",
        "3. **Start Small**: Begin with a focused domain before expanding enterprise-wide\n",
        "4. **Build Expertise**: Train team members on semantic technologies and graph thinking\n",
        "\n",
        "### üõ†Ô∏è Technical Development\n",
        "1. **Production Deployment**: Scale from notebook to enterprise-grade systems\n",
        "2. **Integration Patterns**: Connect semantic graphs with existing data pipelines\n",
        "3. **Performance Optimization**: Implement caching, indexing, and query optimization\n",
        "4. **Security & Governance**: Establish access controls and data lineage tracking\n",
        "\n",
        "## Advanced Topics to Explore\n",
        "\n",
        "### üéì Learning Path\n",
        "- **Ontology Engineering**: Formal methods for knowledge modeling\n",
        "- **Semantic Web Standards**: W3C specifications for interoperability\n",
        "- **Graph Databases**: Neo4j, Amazon Neptune, and other specialized platforms\n",
        "- **Machine Learning**: Embedding semantic graphs in AI/ML workflows\n",
        "\n",
        "### üìö Recommended Resources\n",
        "- **Books**: \"Semantic Web for the Working Ontologist\" by Allemang & Hendler\n",
        "- **Standards**: W3C RDF, OWL, and SPARQL specifications\n",
        "- **Tools**: Prot√©g√© for ontology development, GraphDB for enterprise deployment\n",
        "- **Communities**: Semantic Web community forums and working groups\n",
        "\n",
        "### üåê Industry Applications\n",
        "- **Healthcare**: Clinical decision support and drug discovery\n",
        "- **Finance**: Risk analysis and regulatory reporting\n",
        "- **Manufacturing**: Supply chain optimization and quality management\n",
        "- **Government**: Policy analysis and citizen services\n",
        "\n",
        "## The Future of Intelligent Data\n",
        "\n",
        "Semantic knowledge graphs represent the foundation for truly intelligent information systems. As you've seen, they enable:\n",
        "- **Contextual Understanding**: Data that knows its meaning and relationships\n",
        "- **Adaptive Systems**: Architectures that evolve with changing business needs\n",
        "- **Human-AI Collaboration**: Interfaces that support both human insight and machine intelligence\n",
        "- **Organizational Learning**: Systems that capture and leverage institutional knowledge\n",
        "\n",
        "---\n",
        "\n",
        "**Congratulations!** You've completed a comprehensive introduction to semantic knowledge graphs. The journey from data to insight begins with understanding relationships‚Äîand you now have the tools to build those connections.\n",
        "\n",
        "*Ready to transform your organization's data into intelligent assets? The semantic web awaits your contributions.*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# üìÅ Export and Save Results\n",
        "\n",
        "## ‚ö†Ô∏è Prerequisites - READ THIS FIRST!\n",
        "\n",
        "**Before running the export cell below, you MUST:**\n",
        "\n",
        "1. **Initialize the Knowledge Graph**: Run the cell that contains `kg = SemanticKnowledgeGraph()`\n",
        "2. **Load Data**: Ensure the knowledge graph has been populated with data from your analysis\n",
        "3. **Verify Connection**: The `kg` variable must be available in your notebook session\n",
        "\n",
        "## üéØ What This Export Does\n",
        "\n",
        "This export functionality will generate a comprehensive backup of your semantic knowledge graph analysis including:\n",
        "\n",
        "### üìä RDF Data Formats\n",
        "- **Turtle** (.ttl) - Human-readable RDF format\n",
        "- **XML** (.rdf) - Standard RDF/XML format  \n",
        "- **N-Triples** (.n3) - Line-oriented RDF format\n",
        "- **JSON-LD** (.jsonld) - JSON-based linked data format\n",
        "\n",
        "### üìà Analysis Results\n",
        "- Statistical summaries and insights\n",
        "- Class distribution data\n",
        "- Ontology level analysis\n",
        "- Entity relationship mappings\n",
        "\n",
        "### üé® Visualization Data\n",
        "- Network graph node/edge data\n",
        "- Interactive visualization components\n",
        "- Chart and diagram exports\n",
        "\n",
        "### üìã Summary Report\n",
        "- Comprehensive markdown report\n",
        "- File inventory and descriptions\n",
        "- Integration guidance\n",
        "\n",
        "## üöÄ Expected Output\n",
        "\n",
        "After successful execution, you will have:\n",
        "- All files saved to `semantic_exports/` directory\n",
        "- Timestamped filenames for version control\n",
        "- Ready-to-use data for external systems\n",
        "- Professional documentation for stakeholders\n",
        "\n",
        "## üõë What If It Fails?\n",
        "\n",
        "If you see errors like `name 'kg' is not defined`, it means:\n",
        "1. You haven't run the knowledge graph initialization cell yet\n",
        "2. The notebook session was restarted\n",
        "3. The `kg` variable is out of scope\n",
        "\n",
        "**Solution**: Go back and run the cells that create and populate the knowledge graph first!"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3.12",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}